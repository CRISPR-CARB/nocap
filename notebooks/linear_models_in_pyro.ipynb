{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probablistic linear models using Pyro\n",
    "August George, 2024, PNNL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "$y_i = m_i*x_i + b_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoNormal\n",
    "\n",
    "\n",
    "pyro.set_rng_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the data\n",
    "true_intercept = 1\n",
    "true_slope = 2\n",
    "num_data_points = 100  \n",
    "X_values = torch.linspace(0, 1, num_data_points)\n",
    "Y_values = true_intercept + true_slope * X_values \n",
    "Y_obs_values = Y_values + torch.randn(num_data_points) \n",
    "\n",
    "\n",
    "plt.scatter(X_values, Y_obs_values, label=r'$Y_{obs} = Y_{true} + \\epsilon$, $\\epsilon \\sim \\text{Norm}(0,1)$')\n",
    "plt.plot(X_values, Y_values, color='red', label=r'$Y_{true}$')\n",
    "plt.ylabel('Y')\n",
    "plt.xlabel('X')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian inference using NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(X_values, Y_values):\n",
    "    intercept_prior = pyro.sample('intercept', dist.Normal(0, 10))\n",
    "    slope_prior = pyro.sample('slope', dist.Normal(0, 10))\n",
    "    noise_std_prior = pyro.sample('noise_std', dist.LogNormal(0, 1)) \n",
    "    mean_prediction = intercept_prior + slope_prior * X_values\n",
    "    with pyro.plate('data', len(X_values)):\n",
    "        pyro.sample('observations', dist.Normal(mean_prediction, noise_std_prior), obs=Y_values)\n",
    "\n",
    "# MCMC inference\n",
    "nuts_kernel = NUTS(linear_model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(X_values, Y_obs_values)\n",
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_samples = posterior_samples[\"intercept\"]\n",
    "slope_samples = posterior_samples[\"slope\"]\n",
    "noise_std_samples = posterior_samples[\"noise_std\"]\n",
    "prior_intercept_samples = dist.Normal(0, 10).sample([1000])\n",
    "prior_slope_samples = dist.Normal(0, 10).sample([1000])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.kdeplot(prior_intercept_samples.numpy(), fill=True, color='blue', label='Prior Intercept', ax=axs[0])\n",
    "sns.kdeplot(intercept_samples.numpy(), fill=True, color='orange', label='Posterior Intercept', ax=axs[0])\n",
    "axs[0].set_title('Prior and Posterior Distribution of Intercept')\n",
    "axs[0].set_xlabel('Intercept')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "sns.kdeplot(prior_slope_samples.numpy(), fill=True, color='green', label='Prior Slope', ax=axs[1])\n",
    "sns.kdeplot(slope_samples.numpy(), fill=True, color='red', label='Posterior Slope', ax=axs[1])\n",
    "axs[1].set_title('Prior and Posterior Distribution of Slope')\n",
    "axs[1].set_xlabel('Slope')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "az.plot_trace({\"intercept\": intercept_samples, \"slope\": slope_samples})\n",
    "plt.show()\n",
    "\n",
    "intercept_mean = intercept_samples.mean().item()\n",
    "intercept_std = intercept_samples.std().item()\n",
    "slope_mean = slope_samples.mean().item()\n",
    "slope_std = slope_samples.std().item()\n",
    "noise_std_mean = noise_std_samples.mean().item()\n",
    "noise_std_std = noise_std_samples.std().item()\n",
    "\n",
    "display(f\"MCMC intercept_mean = {intercept_mean}, intercept_std = {intercept_std}\")\n",
    "display(f\"MCMC SVI slope_mean = {slope_mean}, slope_std = {slope_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_guide(X_values, Y_values):\n",
    "    intercept_loc = pyro.param('intercept_loc', torch.tensor(0.0))\n",
    "    intercept_scale = pyro.param('intercept_scale', torch.tensor(1.0), constraint=torch.distributions.constraints.positive)\n",
    "    slope_loc = pyro.param('slope_loc', torch.tensor(0.0))\n",
    "    slope_scale = pyro.param('slope_scale', torch.tensor(1.0), constraint=torch.distributions.constraints.positive)\n",
    "    noise_std_loc = pyro.param('noise_std_loc', torch.tensor(0.0))\n",
    "    noise_std_scale = pyro.param('noise_std_scale', torch.tensor(1.0), constraint=torch.distributions.constraints.positive)\n",
    "    pyro.sample('intercept', dist.Normal(intercept_loc, intercept_scale))\n",
    "    pyro.sample('slope', dist.Normal(slope_loc, slope_scale))\n",
    "    pyro.sample('noise_std', dist.LogNormal(noise_std_loc, noise_std_scale))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam({\"lr\": 0.01})\n",
    "svi_manual = SVI(linear_model, linear_model_guide, optimizer, loss=Trace_ELBO())\n",
    "num_iterations = 1000\n",
    "elbo_values = []  \n",
    "for step in range(num_iterations):\n",
    "    loss = svi_manual.step(X_values, Y_values)\n",
    "    elbo_values.append(loss)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Manual SVI Step {step} : loss = {loss}\")\n",
    "\n",
    "intercept_loc = pyro.param('intercept_loc').item()\n",
    "intercept_scale = pyro.param('intercept_scale').item()\n",
    "slope_loc = pyro.param('slope_loc').item()\n",
    "slope_scale = pyro.param('slope_scale').item()\n",
    "noise_std_loc = torch.tensor(pyro.param('noise_std_loc'))  # Convert to tensor\n",
    "noise_std_scale = torch.tensor(pyro.param('noise_std_scale'))  \n",
    "noise_std_exp = torch.exp(noise_std_loc).item()\n",
    "\n",
    "prior_intercept_samples = dist.Normal(0, 10).sample([1000]).numpy()\n",
    "prior_slope_samples = dist.Normal(0, 10).sample([1000]).numpy()\n",
    "intercept_samples = dist.Normal(intercept_loc, intercept_scale).sample([1000]).numpy()\n",
    "slope_samples = dist.Normal(slope_loc, slope_scale).sample([1000]).numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(elbo_values)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('ELBO (loss)')\n",
    "plt.title('ELBO Plot for Manual SVI')\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 5))\n",
    "sns.kdeplot(prior_intercept_samples, fill=True, color='blue', label='Prior Intercept', ax=axs[0])\n",
    "sns.kdeplot(intercept_samples, fill=True, color='orange', label='Posterior Intercept', ax=axs[0])\n",
    "axs[0].set_title('Prior and Posterior Distribution of Intercept')\n",
    "axs[0].set_xlabel('Intercept')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_slope_samples, fill=True, color='green', label='Prior Slope', ax=axs[1])\n",
    "sns.kdeplot(slope_samples, fill=True, color='orange', label='Posterior Slope', ax=axs[1])\n",
    "axs[1].set_title('Prior and Posterior Distribution of Slope')\n",
    "axs[1].set_xlabel('Slope')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "display(f\"Manual SVI intercept_mean = {intercept_loc}, intercept_std = {intercept_scale}\")\n",
    "display(f\"Manual SVI slope_mean = {slope_loc}, slope_std = {slope_scale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational inference using an autoguide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_guide = AutoNormal(linear_model)\n",
    "optimizer = optim.Adam({\"lr\": 0.01})\n",
    "svi = SVI(linear_model, auto_guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "num_iterations = 1000\n",
    "elbo_values = []  \n",
    "for step in range(num_iterations):\n",
    "    loss = svi.step(X_values, Y_values)\n",
    "    elbo_values.append(loss)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step} : loss = {loss}\")\n",
    "\n",
    "# get samples\n",
    "prior_intercept_samples = dist.Normal(0, 10).sample([1000]).numpy()\n",
    "prior_slope_samples = dist.Normal(0, 10).sample([1000]).numpy()\n",
    "posterior_samples = [auto_guide() for _ in range(1000)]\n",
    "posterior_samples = {k: torch.stack([s[k] for s in posterior_samples]) for k in posterior_samples[0]}\n",
    "intercept_samples = posterior_samples['intercept'].detach().numpy()\n",
    "slope_samples = posterior_samples['slope'].detach().numpy()\n",
    "noise_std_samples = torch.exp(posterior_samples['noise_std']).detach().numpy()\n",
    "intercept_mean = intercept_samples.mean()\n",
    "intercept_std = intercept_samples.std()\n",
    "slope_mean = slope_samples.mean()\n",
    "slope_std = slope_samples.std()\n",
    "noise_std_mean = noise_std_samples.mean()\n",
    "noise_std_std = noise_std_samples.std()\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(elbo_values)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('ELBO (loss)')\n",
    "plt.title('ELBO Plot for Auto SVI')\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 5))\n",
    "sns.kdeplot(prior_intercept_samples, fill=True, color='blue', label='Prior Intercept', ax=axs[0])\n",
    "sns.kdeplot(intercept_samples, fill=True, color='orange', label='Posterior Intercept', ax=axs[0])\n",
    "axs[0].set_title('Prior and Posterior Distribution of Intercept')\n",
    "axs[0].set_xlabel('Intercept')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_slope_samples, fill=True, color='green', label='Prior Slope', ax=axs[1])\n",
    "sns.kdeplot(slope_samples, fill=True, color='orange', label='Posterior Slope', ax=axs[1])\n",
    "axs[1].set_title('Prior and Posterior Distribution of Slope')\n",
    "axs[1].set_xlabel('Slope')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(f\"Auto SVI intercept_mean = {intercept_mean}, intercept_std = {intercept_std}\")\n",
    "display(f\"Auto SVI slope_mean = {slope_mean}, slope_std = {slope_std}\")\n",
    "display(f\"Auto SVI noise_std_mean = {noise_std_mean}, noise_std_std = {noise_std_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear structural causal model from gene regulatory network\n",
    "\n",
    "A --> B\n",
    "\n",
    "B --> C\n",
    "\n",
    "D --| B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "num_samples = 100\n",
    "\n",
    "# Ground truth parameters\n",
    "true_beta_A_B = 2.0\n",
    "true_beta_D_B = -1.0\n",
    "true_beta_B_C = 1.5\n",
    "\n",
    "# Generate synthetic data\n",
    "epsilon_A = torch.normal(0, 1, (num_samples,))\n",
    "epsilon_B = torch.normal(0, 1, (num_samples,))\n",
    "epsilon_C = torch.normal(0, 1, (num_samples,))\n",
    "epsilon_D = torch.normal(0, 1, (num_samples,))\n",
    "\n",
    "A = epsilon_A\n",
    "D = epsilon_D\n",
    "B = true_beta_A_B * A + true_beta_D_B * D + epsilon_B\n",
    "C = true_beta_B_C * B + epsilon_C\n",
    "\n",
    "\n",
    "# Print first few samples for inspection\n",
    "display('Synthetic Data (first 5 samples):')\n",
    "display('A =', A[:5])\n",
    "display('B =', B[:5])\n",
    "display('C =', C[:5])\n",
    "display('D =', D[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_network_model(A, B, C, D, num_samples):\n",
    "    # Priors for parameters\n",
    "    beta_A_B = pyro.sample('beta_A_B', dist.Normal(0, 1))\n",
    "    beta_D_B = pyro.sample('beta_D_B', dist.Normal(0, 1))\n",
    "    beta_B_C = pyro.sample('beta_B_C', dist.Normal(0, 1))\n",
    "    \n",
    "    # Priors for epsilon (noise terms)\n",
    "    epsilon_A = pyro.sample('epsilon_A', dist.Normal(0, 1).expand([num_samples]).to_event(1))\n",
    "    epsilon_B = pyro.sample('epsilon_B', dist.Normal(0, 1).expand([num_samples]).to_event(1))\n",
    "    epsilon_C = pyro.sample('epsilon_C', dist.Normal(0, 1).expand([num_samples]).to_event(1))\n",
    "    epsilon_D = pyro.sample('epsilon_D', dist.Normal(0, 1).expand([num_samples]).to_event(1))\n",
    "    \n",
    "    # Structural equations with uncertainty (noise terms)\n",
    "\n",
    "    # use determinstic to represent \n",
    "    A_model = epsilon_A\n",
    "    D_model = epsilon_D\n",
    "    B_model = beta_A_B * A_model + beta_D_B * D_model + epsilon_B\n",
    "    C_model = beta_B_C * B_model + epsilon_C\n",
    "    \n",
    "    \n",
    "    # Define likelihoods for observed (real) data\n",
    "    with pyro.plate('data', num_samples):\n",
    "        pyro.sample('obs_A', dist.Normal(A_model, 1), obs=A)\n",
    "        pyro.sample('obs_B', dist.Normal(B_model, 1), obs=B)\n",
    "        pyro.sample('obs_C', dist.Normal(C_model, 1), obs=C)\n",
    "        pyro.sample('obs_D', dist.Normal(D_model, 1), obs=D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.render_model(gene_network_model, model_args=(A,  B, C, D, num_samples), render_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.infer.mcmc as mcmc\n",
    "import pyro.infer.mcmc.api as mcmc_api\n",
    "\n",
    "pyro.set_rng_seed(42)\n",
    "\n",
    "# Perform MCMC inference\n",
    "pyro.clear_param_store()\n",
    "kernel = mcmc_api.NUTS(lambda A,  B, C, D: gene_network_model(A,  B, C, D, num_samples), adapt_step_size=True)\n",
    "mcmc_run = mcmc_api.MCMC(kernel, num_samples=1000, warmup_steps=200, num_chains=1)\n",
    "mcmc_run.run(A, B, C, D)\n",
    "\n",
    "# Extract samples\n",
    "mcmc_samples = mcmc_run.get_samples()\n",
    "\n",
    "# Prior samples for comparison\n",
    "prior_sample_size = 1000\n",
    "prior_beta_A_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_D_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_B_C = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "\n",
    "# Posterior samples\n",
    "posterior_beta_A_B = mcmc_samples['beta_A_B'].detach().numpy()\n",
    "posterior_beta_D_B = mcmc_samples['beta_D_B'].detach().numpy()\n",
    "posterior_beta_B_C = mcmc_samples['beta_B_C'].detach().numpy()\n",
    "\n",
    "# Plot KDEs\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.kdeplot(prior_beta_A_B, fill=True, color='blue', label='Prior Beta_A_B', ax=axs[0])\n",
    "sns.kdeplot(posterior_beta_A_B, fill=True, color='orange', label='Posterior Beta_A_B', ax=axs[0])\n",
    "axs[0].axvline(true_beta_A_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_A_B')\n",
    "axs[0].set_title('Prior and Posterior Distribution of Beta_A_B')\n",
    "axs[0].set_xlabel('Beta_A_B')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_D_B, fill=True, color='blue', label='Prior Beta_D_B', ax=axs[1])\n",
    "sns.kdeplot(posterior_beta_D_B, fill=True, color='orange', label='Posterior Beta_D_B', ax=axs[1])\n",
    "axs[1].axvline(true_beta_D_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_D_B')\n",
    "axs[1].set_title('Prior and Posterior Distribution of Beta_D_B')\n",
    "axs[1].set_xlabel('Beta_D_B')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_B_C, fill=True, color='blue', label='Prior Beta_B_C', ax=axs[2])\n",
    "sns.kdeplot(posterior_beta_B_C, fill=True, color='orange', label='Posterior Beta_B_C', ax=axs[2])\n",
    "axs[2].axvline(true_beta_B_C, color='black', linestyle='dashed', linewidth=1, label='True Beta_B_C')\n",
    "axs[2].set_title('Prior and Posterior Distribution of Beta_B_C')\n",
    "axs[2].set_xlabel('Beta_B_C')\n",
    "axs[2].set_ylabel('Density')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the guide\n",
    "guide = AutoNormal(gene_network_model)\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
    "\n",
    "# Set up the SVI object\n",
    "svi = SVI(gene_network_model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# Number of training steps\n",
    "num_steps = 10000\n",
    "\n",
    "# Run SVI\n",
    "pyro.clear_param_store()\n",
    "for step in range(num_steps):\n",
    "    svi.step(A,  B, C, D, num_samples)\n",
    "    if step % 500 == 0:\n",
    "        elbo = svi.evaluate_loss(A, B, C,  D, num_samples)\n",
    "        print(f'Step {step} - ELBO: {elbo}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "\n",
    "# Use Predictive to get posterior samples\n",
    "predictive = Predictive(guide, num_samples=1000)\n",
    "posterior_samples = predictive(A,  B, C, D, num_samples)\n",
    "posterior_beta_A_B = posterior_samples['beta_A_B'].detach().numpy()\n",
    "posterior_beta_D_B = posterior_samples['beta_D_B'].detach().numpy()\n",
    "posterior_beta_B_C = posterior_samples['beta_B_C'].detach().numpy()\n",
    "\n",
    "# Prior samples for comparison\n",
    "prior_sample_size = 1000\n",
    "prior_beta_A_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_D_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_B_C = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "\n",
    "# Plot KDEs\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.kdeplot(prior_beta_A_B, fill=True, color='blue', label='Prior Beta_A_B', ax=axs[0])\n",
    "sns.kdeplot(posterior_beta_A_B, fill=True, color='orange', label='Posterior Beta_A_B', ax=axs[0])\n",
    "axs[0].axvline(true_beta_A_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_A_B')\n",
    "axs[0].set_title('Prior and Posterior Distribution of Beta_A_B')\n",
    "axs[0].set_xlabel('Beta_A_B')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_D_B, fill=True, color='blue', label='Prior Beta_D_B', ax=axs[1])\n",
    "sns.kdeplot(posterior_beta_D_B, fill=True, color='orange', label='Posterior Beta_D_B', ax=axs[1])\n",
    "axs[1].axvline(true_beta_D_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_D_B')\n",
    "axs[1].set_title('Prior and Posterior Distribution of Beta_D_B')\n",
    "axs[1].set_xlabel('Beta_D_B')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_B_C, fill=True, color='blue', label='Prior Beta_B_C', ax=axs[2])\n",
    "sns.kdeplot(posterior_beta_B_C, fill=True, color='orange', label='Posterior Beta_B_C', ax=axs[2])\n",
    "axs[2].axvline(true_beta_B_C, color='black', linestyle='dashed', linewidth=1, label='True Beta_B_C')\n",
    "axs[2].set_title('Prior and Posterior Distribution of Beta_B_C')\n",
    "axs[2].set_xlabel('Beta_B_C')\n",
    "axs[2].set_ylabel('Density')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVI with multinormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.infer.autoguide import AutoNormal, AutoMultivariateNormal, AutoNormalizingFlow, AutoLowRankMultivariateNormal\n",
    "from pyro.distributions.transforms import AffineAutoregressive\n",
    "import pyro.optim  # Ensure that Pyro's optim module is imported\n",
    "from pyro.optim import Adam, PyroLRScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "pyro.set_rng_seed(40)\n",
    "\n",
    "# Define the guide\n",
    "guide = AutoMultivariateNormal(gene_network_model)\n",
    "#guide = AutoNormal(gene_network_model)\n",
    "\n",
    "\n",
    "# # Set up the optimizer\n",
    "# adam_params = {\"lr\": 0.001}\n",
    "# scheduler_params = {\n",
    "#     \"optimizer\": torch.optim.Adam,\n",
    "#     \"optim_args\": adam_params,\n",
    "#     \"step_size\": 5000,  \n",
    "#     \"gamma\": 0.3  \n",
    "# }\n",
    "# scheduler = pyro.optim.StepLR(scheduler_params)\n",
    "\n",
    "scheduler =  Adam({\"lr\": 0.001})  # Use a constant learning rate\n",
    "\n",
    "# Set up the SVI object\n",
    "svi = SVI(gene_network_model, guide, scheduler, loss=Trace_ELBO())\n",
    "\n",
    "# Number of training steps\n",
    "num_steps = 2000\n",
    "\n",
    "# Run SVI with progress bar\n",
    "pyro.clear_param_store()\n",
    "elbos = []\n",
    "with tqdm(total=num_steps, desc=\"SVI Training Progress\") as pbar:\n",
    "    for step in range(num_steps):\n",
    "        elbo = svi.step(A,B, C,  D, num_samples)\n",
    "        elbos.append(elbo)\n",
    "        if step % 100 == 0:\n",
    "            pbar.set_postfix(ELBO=elbo)\n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "# Plot ELBOs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(elbos)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('ELBO')\n",
    "plt.title('ELBO over Time')\n",
    "plt.show()\n",
    "\n",
    "# Posterior predictive checks\n",
    "predictive = Predictive(guide, num_samples=1000)\n",
    "posterior_samples = predictive(A=A, B=B, C=C, D=D, num_samples=num_samples)\n",
    "\n",
    "posterior_beta_A_B = posterior_samples['beta_A_B'].detach().numpy().flatten()\n",
    "posterior_beta_D_B = posterior_samples['beta_D_B'].detach().numpy().flatten()\n",
    "posterior_beta_B_C = posterior_samples['beta_B_C'].detach().numpy().flatten()\n",
    "\n",
    "# Prior samples for comparison\n",
    "prior_sample_size = 1000\n",
    "prior_beta_A_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_D_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_B_C = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "\n",
    "# Plot KDEs\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.kdeplot(prior_beta_A_B, fill=True, color='blue', label='Prior Beta_A_B', ax=axs[0])\n",
    "sns.kdeplot(posterior_beta_A_B, fill=True, color='orange', label='Posterior Beta_A_B', ax=axs[0])\n",
    "axs[0].axvline(true_beta_A_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_A_B')\n",
    "axs[0].set_title('Prior and Posterior Distribution of Beta_A_B')\n",
    "axs[0].set_xlabel('Beta_A_B')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_D_B, fill=True, color='blue', label='Prior Beta_D_B', ax=axs[1])\n",
    "sns.kdeplot(posterior_beta_D_B, fill=True, color='orange', label='Posterior Beta_D_B', ax=axs[1])\n",
    "axs[1].axvline(true_beta_D_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_D_B')\n",
    "axs[1].set_title('Prior and Posterior Distribution of Beta_D_B')\n",
    "axs[1].set_xlabel('Beta_D_B')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_B_C, fill=True, color='blue', label='Prior Beta_B_C', ax=axs[2])\n",
    "sns.kdeplot(posterior_beta_B_C, fill=True, color='orange', label='Posterior Beta_B_C', ax=axs[2])\n",
    "axs[2].axvline(true_beta_B_C, color='black', linestyle='dashed', linewidth=1, label='True Beta_B_C')\n",
    "axs[2].set_title('Prior and Posterior Distribution of Beta_B_C')\n",
    "axs[2].set_xlabel('Beta_B_C')\n",
    "axs[2].set_ylabel('Density')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding technical noise to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a pyro module\n",
    "\n",
    "Goal: use a simple linear model to validate a probablistic model for biological and observational processes.\n",
    "\n",
    "### The biological process model\n",
    "$A$ regulates $B$ (A-->B), which is represented with a linear model: $A = \\epsilon_A$ and $B = \\beta_{AB}A + \\epsilon_B$.\n",
    "\n",
    "$\\epsilon_A$ and $\\epsilon_B$ represent biological noise and are sampled from Normal(0,1).\n",
    "\n",
    "$\\beta_{AB}$ represents the strength of the regulation between $A$ and $B$.\n",
    "\n",
    "### The observational model\n",
    "Our observations are not from the biological model directly, but include technical noise from the experiment. \n",
    "\n",
    "The observed gene expression values are a function of the biological and observational/technical processes: \n",
    "$A_{obs} = f(A, \\theta_{bio}^A, \\theta_{obs}^A)$ and \n",
    "$B_{obs} = f(B, \\theta_{bio}^B, \\theta_{obs}^B)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from pyro.nn import PyroModule, PyroSample, PyroParam\n",
    "\n",
    "class BiologicalProcess(PyroModule):\n",
    "    def __init__(self, num_samples=100, beta_AB_true=2):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.register_buffer('beta_AB_true',torch.tensor(beta_AB_true) )\n",
    "\n",
    "    @PyroSample\n",
    "    def epsilon_A(self):\n",
    "        return dist.Normal(0, 1).expand([self.num_samples]).to_event(1)\n",
    "\n",
    "    @PyroSample\n",
    "    def epsilon_B(self):\n",
    "        return dist.Normal(0, 1).expand([self.num_samples]).to_event(1)\n",
    "\n",
    "    @PyroSample\n",
    "    def beta_AB(self):\n",
    "        return dist.Normal(0, 1).expand([self.num_samples]).to_event(1)\n",
    "\n",
    "    def forward(self):\n",
    "        A_bio = pyro.deterministic('A_bio', torch.clamp(self.epsilon_A, min=0))\n",
    "        B_bio = pyro.deterministic('B_bio', torch.clamp(self.beta_AB * A_bio + self.epsilon_B, min=0))\n",
    "        return A_bio, B_bio\n",
    "\n",
    "\n",
    "class TechnicalNoiseProcess(PyroModule):\n",
    "    def __init__(self, biological_model, k=1, q=0.5, epsilon=1e-8):\n",
    "        super().__init__()\n",
    "        self.biological_model = biological_model\n",
    "        self.register_buffer(\"k\", torch.tensor(k))  \n",
    "        self.register_buffer(\"q\", torch.tensor(q))  \n",
    "        self.register_buffer(\"eps\", torch.tensor(epsilon))  \n",
    "\n",
    "    def forward(self, A_obs=torch.as_tensor(1.0), B_obs=torch.as_tensor(1.0), return_generated=False):\n",
    "        A_bio, B_bio = self.biological_model()\n",
    "\n",
    "        A_obs_mask = ~A_obs.isnan()\n",
    "        B_obs_mask = ~B_obs.isnan()\n",
    "\n",
    "        with pyro.plate('data', self.biological_model.num_samples):\n",
    "\n",
    "            A_UMI_obs = pyro.sample('A_UMI_obs', dist.Poisson(A_bio+self.eps), obs=A_obs, obs_mask=A_obs_mask)\n",
    "            B_UMI_obs = pyro.sample('B_UMI_obs', dist.Poisson(B_bio+self.eps), obs=B_obs, obs_mask=B_obs_mask)\n",
    "\n",
    "        if return_generated:\n",
    "            return A_UMI_obs, B_UMI_obs\n",
    "\n",
    "# Instantiate and run the technical noise process model with the biological model\n",
    "biological_model = BiologicalProcess(num_samples=100)\n",
    "pyro.render_model(biological_model, render_distributions=True, render_deterministic=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_noise_process = TechnicalNoiseProcess(biological_model)\n",
    "pyro.render_model(technical_noise_process, render_distributions=True, render_deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples \n",
    "beta_AB_true = biological_model.beta_AB_true.detach().cpu().numpy()\n",
    "A_obs_tensor, B_obs_tensor = technical_noise_process(return_generated=True)\n",
    "A_obs = A_obs_tensor.detach()\n",
    "B_obs = B_obs_tensor.detach()\n",
    "\n",
    "display(A_obs[:100])\n",
    "display(B_obs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.poutine as poutine\n",
    "from pyro.infer import SVI, TraceEnum_ELBO\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal\n",
    "\n",
    "beta_AB_true = biological_model.beta_AB_true.detach().cpu().numpy()\n",
    "A_obs_tensor, B_obs_tensor = technical_noise_process.forward(return_generated=True)\n",
    "A_obs = A_obs_tensor.detach()\n",
    "B_obs = B_obs_tensor.detach()\n",
    "\n",
    "display(f'True beta_AB: {beta_AB_true}')\n",
    "display(type(A_obs))\n",
    "\n",
    "\n",
    "# Define the model to be used for inference\n",
    "def model(A_obs, B_obs):\n",
    "    biological_model = BiologicalProcess(num_samples=100)\n",
    "    technical_model = TechnicalNoiseProcess(biological_model)\n",
    "    technical_model.forward(A_obs=A_obs, B_obs=B_obs)\n",
    "\n",
    "# Define a guide that allows enumeration of discrete variables\n",
    "guide = AutoMultivariateNormal(poutine.block(model, hide=['dropout_binary_indicator_A', 'dropout_binary_indicator_B']))\n",
    "\n",
    "# Use TraceEnum_ELBO to handle discrete enumeration\n",
    "optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "\n",
    "svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# Run SVI\n",
    "num_steps = 2000\n",
    "losses = []\n",
    "for step in range(num_steps):\n",
    "    loss = svi.step(A_obs, B_obs)\n",
    "    losses.append(loss)\n",
    "    if step % 500 == 0:\n",
    "        print(f\"Step {step} : loss = {loss}\")\n",
    "        \n",
    "# Plot the loss curve\n",
    "plt.plot(losses)\n",
    "plt.xlabel('SVI step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.show()\n",
    "\n",
    "# Extract learned parameters from the AutoGuide\n",
    "posterior_samples = guide.get_posterior().sample((1000,))\n",
    "\n",
    "# Generate prior samples for beta_AB\n",
    "prior_samples = dist.Normal(0, 1).sample((1000,)).numpy()\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(posterior_samples.flatten(), bins=30, density=True, alpha=0.6, color='k', label='Learned beta_AB posterior')\n",
    "plt.hist(prior_samples, bins=30, density=True, alpha=0.6, color='b', label='Prior beta_AB')\n",
    "plt.axvline(x=beta_AB_true, color='r', linestyle='--', label='True beta_AB')\n",
    "plt.xlabel('beta_AB')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Posterior and Prior Distribution of beta_AB')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generalized linear structural causal model \n",
    "\n",
    "$\\vec{y} = \\underset{n \\times n}\\Alpha\\vec{x} + \\vec{\\epsilon}$\n",
    "\n",
    "example $A\\rightarrow B$:\n",
    "\n",
    "\n",
    "$y_A = \\epsilon_A$\n",
    "\n",
    "$y_B = \\alpha_{AB}\\cdot A  + \\epsilon_B$\n",
    "\n",
    "$\\vec{y} = [y_A, y_B]$\n",
    "\n",
    "$\\underset{2\\times 2} \\Alpha = \\begin{bmatrix}0 & \\alpha_{AB} \\\\ 0&0 \\end{bmatrix}$\n",
    "\n",
    "$\\vec{\\epsilon} = [\\epsilon_A, \\epsilon_B]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graph = nx.DiGraph()\n",
    "graph.add_edge('A', 'B')\n",
    "adj_matrix_dense = nx.adjacency_matrix(graph).toarray()\n",
    "adj_matrix_dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph (DiGraph)\n",
    "G = nx.DiGraph()\n",
    "G.add_edge(0, 1)\n",
    "G.add_edge(1, 2)\n",
    "G.add_edge(2, 0)\n",
    "G.add_edge(2, 3)\n",
    "\n",
    "# Plot the visual graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "nx.draw(G, with_labels=True, node_color='skyblue', node_size=2000, edge_color='k', font_size=15, font_color='black', font_weight='bold')\n",
    "plt.title('Graph Visualization')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Get the adjacency matrix as a dense NumPy array\n",
    "adj_matrix_dense = nx.adjacency_matrix(G).toarray()\n",
    "display(adj_matrix_dense)\n",
    "\n",
    "\n",
    "# Convert the dense NumPy array to a PyTorch sparse tensor\n",
    "adj_matrix_dense = torch.tensor(adj_matrix_dense, dtype=torch.float32)\n",
    "adj_matrix_sparse = adj_matrix_dense.to_sparse()\n",
    "display(adj_matrix_sparse)\n",
    "\n",
    "\n",
    "# Define a simple model using the sparse adjacency matrix\n",
    "def model(adj_matrix_sparse):\n",
    "    num_nodes = adj_matrix_sparse.size(0)\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if (adj_matrix_sparse._indices() == torch.tensor([[i], [j]])).all(dim=0).any():\n",
    "                # Sample from a distribution for nonzero elements\n",
    "                pyro.sample(f\"alpha_{i}_{j}\", dist.Normal(0, 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Trace the model execution\n",
    "trace = poutine.trace(model).get_trace(adj_matrix_sparse)\n",
    "\n",
    "# Print the trace\n",
    "for name, site in trace.nodes.items():\n",
    "    if site[\"type\"] == \"sample\":\n",
    "        print(f\"{name}: {site['value']}\")\n",
    "\n",
    "pyro.render_model(model, model_args=(adj_matrix_sparse,), render_distributions=True, render_deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adjacency matrix: tensor([[0, 1, 0, 1],\\n        [0, 0, 1, 0],\\n        [0, 0, 0, 0],\\n        [0, 0, 0, 0]])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"560pt\" height=\"414pt\"\n",
       " viewBox=\"0.00 0.00 560.05 413.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 409.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-409.5 556.05,-409.5 556.05,4 -4,4\"/>\n",
       "<!-- epsilon_A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>epsilon_A</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"256.28\" cy=\"-310.75\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.28\" y=\"-305.7\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_A</text>\n",
       "</g>\n",
       "<!-- A -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"256.28\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n",
       "</g>\n",
       "<!-- epsilon_A&#45;&gt;A -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>epsilon_A&#45;&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256.28,-292.34C256.28,-267.52 256.28,-221.65 256.28,-191.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.78,-191.9 256.28,-181.9 252.78,-191.9 259.78,-191.9\"/>\n",
       "</g>\n",
       "<!-- epsilon_B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>epsilon_B</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"48.28\" cy=\"-162\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"48.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_B</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"215.28\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.28\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n",
       "</g>\n",
       "<!-- epsilon_B&#45;&gt;B -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>epsilon_B&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M79.3,-148C108.62,-135.71 152.46,-117.33 182.38,-104.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.45,-108.14 191.32,-101.04 180.75,-101.68 183.45,-108.14\"/>\n",
       "</g>\n",
       "<!-- epsilon_C -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>epsilon_C</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"390.28\" cy=\"-90\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.28\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_C</text>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"390.28\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.28\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- epsilon_C&#45;&gt;C -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>epsilon_C&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M390.28,-71.7C390.28,-64.41 390.28,-55.73 390.28,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"393.78,-47.62 390.28,-37.62 386.78,-47.62 393.78,-47.62\"/>\n",
       "</g>\n",
       "<!-- epsilon_D -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>epsilon_D</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"350.28\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"350.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_D</text>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"297.28\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.28\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- epsilon_D&#45;&gt;D -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>epsilon_D&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M337.72,-144.41C331.2,-135.8 323.11,-125.11 315.88,-115.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"318.76,-113.58 309.94,-107.72 313.18,-117.8 318.76,-113.58\"/>\n",
       "</g>\n",
       "<!-- beta_A_B -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>beta_A_B</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"163.28\" cy=\"-162\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_A_B</text>\n",
       "</g>\n",
       "<!-- beta_A_B&#45;&gt;B -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>beta_A_B&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M175.6,-144.41C182,-135.8 189.94,-125.11 197.04,-115.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.7,-117.84 202.86,-107.73 194.08,-113.67 199.7,-117.84\"/>\n",
       "</g>\n",
       "<!-- beta_A_D -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>beta_A_D</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"466.28\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"466.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_A_D</text>\n",
       "</g>\n",
       "<!-- beta_A_D&#45;&gt;D -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>beta_A_D&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M432.98,-148.39C405.93,-137.99 366.9,-122.62 333.28,-108 331.78,-107.35 330.24,-106.67 328.69,-105.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"330.42,-102.92 319.88,-101.92 327.5,-109.28 330.42,-102.92\"/>\n",
       "</g>\n",
       "<!-- beta_B_C -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>beta_B_C</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"504.28\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"504.28\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_B_C</text>\n",
       "</g>\n",
       "<!-- beta_B_C&#45;&gt;C -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>beta_B_C&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M480.1,-74.15C462.26,-63.2 437.92,-48.25 419.07,-36.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"421.16,-33.85 410.8,-31.6 417.49,-39.82 421.16,-33.85\"/>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.77,-144.76C241.91,-136.46 235.87,-126.15 230.39,-116.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.58,-115.31 225.5,-108.45 227.54,-118.85 233.58,-115.31\"/>\n",
       "</g>\n",
       "<!-- A&#45;&gt;D -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>A&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.79,-144.76C270.65,-136.46 276.69,-126.15 282.17,-116.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"285.02,-118.85 287.06,-108.45 278.98,-115.31 285.02,-118.85\"/>\n",
       "</g>\n",
       "<!-- B&#45;&gt;C -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>B&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.16,-79.85C268.42,-67.74 321.99,-46.32 356.8,-32.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"358.01,-35.68 365.99,-28.72 355.41,-29.18 358.01,-35.68\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-388.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_A ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-371.7\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_B ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-355.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_C ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-338.7\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_D ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-322.2\" font-family=\"Times,serif\" font-size=\"14.00\">beta_A_B ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-305.7\" font-family=\"Times,serif\" font-size=\"14.00\">beta_A_D ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-289.2\" font-family=\"Times,serif\" font-size=\"14.00\">beta_B_C ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-272.7\" font-family=\"Times,serif\" font-size=\"14.00\">A ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-256.2\" font-family=\"Times,serif\" font-size=\"14.00\">B ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-239.7\" font-family=\"Times,serif\" font-size=\"14.00\">C ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-223.2\" font-family=\"Times,serif\" font-size=\"14.00\">D ~ Deterministic</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1612277d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "\n",
    "\n",
    "def linear_structural_causal_model(adjacency_matrix, node_names):    \n",
    "    # Initialize a dictionary to store the sampled values\n",
    "    state_variables = {}\n",
    "    \n",
    "    # Sample noise for each state variable\n",
    "    noise = {name: pyro.sample(f\"epsilon_{name}\", dist.Normal(0, 1)) for name in node_names}\n",
    "    \n",
    "    # Prior distributions for the beta parameters (relationship strengths)\n",
    "    beta = {f\"beta_{parent}_{child}\": pyro.sample(f\"beta_{parent}_{child}\", dist.Normal(0, 1)) \n",
    "            for i, parent in enumerate(node_names) for j, child in enumerate(node_names) if adjacency_matrix[i][j] == 1}\n",
    "    \n",
    "    # Calculate the values of state variables based on their parents\n",
    "    for j, child in enumerate(node_names):\n",
    "        parent_sum = 0.0\n",
    "        for i, parent in enumerate(node_names):\n",
    "            if adjacency_matrix[i][j] == 1:\n",
    "                parent_sum += beta[f\"beta_{parent}_{child}\"] * state_variables.get(parent, noise[parent])\n",
    "        state_variables[child] = pyro.deterministic(child, parent_sum + noise[child])\n",
    "    \n",
    "    return state_variables\n",
    "\n",
    "\n",
    "\n",
    "# Define the DAG using an adjacency matrix (A -> B -> C, A -> D)\n",
    "adj_matrix = torch.tensor([[0, 1, 0, 1],  # A\n",
    "                           [0, 0, 1, 0],  # B\n",
    "                           [0, 0, 0, 0],  # C\n",
    "                           [0, 0, 0, 0]]) # D\n",
    "\n",
    "display(f\"adjacency matrix: {adj_matrix}\")\n",
    "\n",
    "node_names = ['A', 'B', 'C', 'D']\n",
    "\n",
    "# Create a directed graph (DiGraph)\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([('A', 'B'), ('B', 'C'), ('A', 'D')])\n",
    "\n",
    "# Plot the visual graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "nx.draw(G, with_labels=True, node_color='skyblue', node_size=2000, edge_color='k', font_size=15, font_color='black', font_weight='bold')\n",
    "plt.title('Graph Visualization')\n",
    "plt.show()\n",
    "\n",
    "# Generate the probabilistic model\n",
    "pyro.clear_param_store()  # Clear the parameter store\n",
    "model = lambda: linear_structural_causal_model(adj_matrix, node_names)\n",
    "\n",
    "# Visualize the model\n",
    "pyro.render_model(model, render_distributions=True, render_deterministic=True, filename=\"LSCM_graph.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[z, y, x]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import sympy as sy\n",
    "import sympytorch\n",
    "\n",
    "# # TODO: extra funcs argument in sympytorch.SymPyModule?\n",
    "# def solve_lscm(sympy_symbol_params, sympy_lscm):\n",
    "#     eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]   \n",
    "#     sympy_out = sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "    \n",
    "#     return sympy_out\n",
    "\n",
    "# solve_lscm(sympy_symbol_params, sympy_lscm)\n",
    "\n",
    "\n",
    "# Define the LSCM symbols and equations\n",
    "x, y, z, beta_xy, beta_yz, epsilon_x, epsilon_y, epsilon_z = sy.symbols('x y z beta_xy beta_yz epsilon_x epsilon_y epsilon_z')\n",
    "sympy_lscm = {\n",
    "    z: epsilon_z,\n",
    "    y: beta_yz * z + epsilon_y,\n",
    "    x: beta_xy * y + epsilon_x,\n",
    "}\n",
    "\n",
    "# networkx graph \n",
    "G = nx.DiGraph()\n",
    "G.add_edge(z, y)\n",
    "G.add_edge(y, x)\n",
    "sorted_nodes = list(nx.topological_sort(G))\n",
    "display(sorted_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[z, y, x]\n",
      "[epsilon_z, beta_yz*z + epsilon_y, beta_xy*y + epsilon_x]\n"
     ]
    }
   ],
   "source": [
    "substituted_nodes = []\n",
    "for node in sorted_nodes:\n",
    "    substituted_nodes.append(node.subs(node,sympy_lscm[node]))\n",
    "\n",
    "\n",
    "print(sorted_nodes)\n",
    "print(substituted_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:229\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: _Node(\n  (_args): ModuleList(\n    (0-1): 2 x _Node()\n  )\n)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:229\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: _Node()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:229\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: <function _Node.__init__.<locals>.<lambda> at 0x1631b99e0>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m tensor_params \u001b[38;5;241m=\u001b[39m {param: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mfloat\u001b[39m(val), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat) \u001b[38;5;28;01mfor\u001b[39;00m param, val \u001b[38;5;129;01min\u001b[39;00m sympy_string_params\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Run the module with the tensor parameters\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m sympytorch_out \u001b[38;5;241m=\u001b[39m lscm_module(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtensor_params)\n\u001b[1;32m     29\u001b[0m display(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msympy_expressions:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msympy_expressions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m display(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msympy_torch_output:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msympytorch_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:264\u001b[0m, in \u001b[0;36mSymPyModule.forward\u001b[0;34m(self, **symbols)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msymbols: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 264\u001b[0m     out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:264\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msymbols: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 264\u001b[0m     out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:231\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m arg(memodict)\n\u001b[1;32m    232\u001b[0m     memodict[arg] \u001b[38;5;241m=\u001b[39m arg_\n\u001b[1;32m    233\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(arg_)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:231\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m arg(memodict)\n\u001b[1;32m    232\u001b[0m     memodict[arg] \u001b[38;5;241m=\u001b[39m arg_\n\u001b[1;32m    233\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(arg_)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:231\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m arg(memodict)\n\u001b[1;32m    232\u001b[0m     memodict[arg] \u001b[38;5;241m=\u001b[39m arg_\n\u001b[1;32m    233\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(arg_)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:164\u001b[0m, in \u001b[0;36m_Node.__init__.<locals>.<lambda>\u001b[0;34m(memodict)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m value: value\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28;01mlambda\u001b[39;00m memodict: memodict[expr\u001b[38;5;241m.\u001b[39mname]),)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_func \u001b[38;5;241m=\u001b[39m _func_lookup[expr\u001b[38;5;241m.\u001b[39mfunc]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'z'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Substitute the equations to the variables\n",
    "# z = epsilon_z\n",
    "# y = beta_yz * z + epsilon_y\n",
    "# x = beta_xy * y + epsilon_x\n",
    "\n",
    "# Create a list of sympy expressions\n",
    "#sympy_expressions = [z,y,x]\n",
    "\n",
    "sympy_expressions = substituted_nodes\n",
    "\n",
    "# Define parameter values\n",
    "sympy_string_params = {\n",
    "    beta_xy.name: 1.0,\n",
    "    beta_yz.name: 1.0,\n",
    "    epsilon_x.name: 0.1,\n",
    "    epsilon_y.name: 0.1,\n",
    "    epsilon_z.name: 0.1\n",
    "}\n",
    "\n",
    "\n",
    "# Create a sympytorch module from the sympy expressions\n",
    "lscm_module = sympytorch.SymPyModule(expressions=sympy_expressions)\n",
    "\n",
    "# Convert the sympy string parameters to torch tensors\n",
    "tensor_params = {param: torch.tensor(float(val), dtype=torch.float) for param, val in sympy_string_params.items()}\n",
    "\n",
    "# Run the module with the tensor parameters\n",
    "sympytorch_out = lscm_module(**tensor_params)\n",
    "display(f\"sympy_expressions:{sympy_expressions}\")\n",
    "display(f\"sympy_torch_output:{sympytorch_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{x: 0.300000000000000, y: 0.200000000000000, z: 0.100000000000000}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Solve in sympy for comparison\n",
    "sympy_symbol_params = {\n",
    "    beta_xy: 1.0,\n",
    "    beta_yz: 1.0,\n",
    "    epsilon_x: 0.1,\n",
    "    epsilon_y: 0.1,\n",
    "    epsilon_z: 0.1\n",
    "}\n",
    "eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]\n",
    "sympy_out = sy.solve(eqns, list(sympy_lscm), rational=False, dict=False)\n",
    "\n",
    "sympy_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_function():\n",
    "    x, y = sy.symbols(\"x y\")\n",
    "    f = sy.Function(\"f\")\n",
    "    z = x + f(y)\n",
    "    extra_funcs = {f: lambda y_: y_**2}\n",
    "    mod = sympytorch.SymPyModule(expressions=[z], extra_funcs=extra_funcs)\n",
    "    assert mod.sympy() == [z]\n",
    "    assert mod(x=1, y=2) == 1 + 2**2\n",
    "\n",
    "test_custom_function()\n",
    "\n",
    "\n",
    "def test_lscm_function():\n",
    "    x, y, epsilon_x, epsilon_y, beta_xy = sy.symbols(\"x y epsilon_x epsilon_y beta_xy\")\n",
    "    #f = sy.Function(\"f\")\n",
    "    #solution = f(((x,epsilon_x), (y,x*beta_xy+epsilon_y)))\n",
    "    \n",
    "    def solve_lscm(sympy_lscm):\n",
    "        eqns = [sy.Eq(lhs,rhs) for lhs, rhs in sympy_lscm]\n",
    "        #eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]  \n",
    "        return sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "    \n",
    "    #extra_funcs = {f: solve_lscm}\n",
    "    sympy_lscm = ((x,epsilon_x), (y,x*beta_xy+epsilon_y))\n",
    "    eqns = [sy.Eq(lhs,rhs) for lhs, rhs in sympy_lscm]\n",
    "    expressions = sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "    mod = sympytorch.SymPyModule(expressions=expressions)\n",
    "    return mod\n",
    "\n",
    "mod = test_lscm_function()\n",
    "\n",
    "\n",
    "# def solve_lscm(sympy_symbol_params, sympy_lscm):\n",
    "#     eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]   \n",
    "#     sympy_out = sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "    \n",
    "#     return sympy_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m mod(epsilon_x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.1\u001b[39m), epsilon_y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.1\u001b[39m), beta_xy\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m))\n\u001b[1;32m      2\u001b[0m out\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:266\u001b[0m, in \u001b[0;36mSymPyModule.forward\u001b[0;34m(self, **symbols)\u001b[0m\n\u001b[1;32m    264\u001b[0m out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "out = mod(epsilon_x=torch.tensor(0.1), epsilon_y=torch.tensor(0.1), beta_xy=torch.tensor(1.0))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[z, y, x]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sympy_lscm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for var, rhs in sympy_lscm.items():\n",
    "    var = rhs\n",
    "\n",
    "sympy_expressions = [z,y,x]\n",
    "\n",
    "display(sympy_expressions)\n",
    "display(z)\n",
    "\n",
    "# Define parameter values\n",
    "sympy_string_params = {\n",
    "    beta_xy.name: 1.0,\n",
    "    beta_yz.name: 1.0,\n",
    "    epsilon_x.name: 0.1,\n",
    "    epsilon_y.name: 0.1,\n",
    "    epsilon_z.name: 0.1\n",
    "}\n",
    "\n",
    "sympy_symbol_params = {\n",
    "    beta_xy: 1.0,\n",
    "    beta_yz: 1.0,\n",
    "    epsilon_x: 0.1,\n",
    "    epsilon_y: 0.1,\n",
    "    epsilon_z: 0.1\n",
    "}\n",
    "\n",
    "tensor_params = {param: torch.tensor(float(val), dtype=torch.float) for param, val in sympy_string_params.items()}\n",
    "\n",
    "lscm_module = sympytorch.SymPyModule(expressions=sympy_expressions)\n",
    "\n",
    "display(lscm_module.sympy())\n",
    "\n",
    "sympytorch_out = lscm_module(**tensor_params)\n",
    "\n",
    "display(sympy_expressions)\n",
    "display(sympytorch_out)\n",
    "\n",
    "eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]\n",
    "sympy_out = sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "\n",
    "display(sympy_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define parameter values\n",
    "sympy_params = {\n",
    "    beta_xy.name: 1.0,\n",
    "    beta_yz.name: 1.0,\n",
    "    epsilon_x.name: 0.1,\n",
    "    epsilon_y.name: 0.1,\n",
    "    epsilon_z.name: 0.1\n",
    "}\n",
    "\n",
    "tensor_params = {param: torch.tensor(float(val), dtype=torch.float) for param, val in sympy_params.items()}\n",
    "\n",
    "lscm_module = sympytorch.SymPyModule(expressions=sympy_expressions)\n",
    "\n",
    "# dictionary of all of the sympy symbols: string name : symbol\n",
    "\n",
    "lscm_module.sympy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# substitute the parameter values into the sympy expressions\n",
    "out = lscm_module(**tensor_params)\n",
    "\n",
    "display(out)\n",
    "\n",
    "\n",
    "# Create the probabilistic graphical model\n",
    "#pg_model = create_pg_model(lscm, params)\n",
    "\n",
    "# Visualize the model\n",
    "#pyro.render_model(lscm_module, render_distributions=True, render_deterministic=True)\n",
    "\n",
    "# # Sample from the model\n",
    "# samples = sample_from_model(pg_model, num_samples=1000)\n",
    "\n",
    "# print(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:229\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: <function _Node.__init__.<locals>.<lambda> at 0x1632ab380>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m X_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate Y using the compiled function\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m Y_tensor \u001b[38;5;241m=\u001b[39m sympy_Y(X\u001b[38;5;241m=\u001b[39mX_tensor)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed Y:\u001b[39m\u001b[38;5;124m\"\u001b[39m, Y_tensor)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate Z using the compiled function, substituting Y\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:264\u001b[0m, in \u001b[0;36mSymPyModule.forward\u001b[0;34m(self, **symbols)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msymbols: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 264\u001b[0m     out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:264\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msymbols: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 264\u001b[0m     out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:231\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m arg(memodict)\n\u001b[1;32m    232\u001b[0m     memodict[arg] \u001b[38;5;241m=\u001b[39m arg_\n\u001b[1;32m    233\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(arg_)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:164\u001b[0m, in \u001b[0;36m_Node.__init__.<locals>.<lambda>\u001b[0;34m(memodict)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m value: value\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28;01mlambda\u001b[39;00m memodict: memodict[expr\u001b[38;5;241m.\u001b[39mname]),)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_func \u001b[38;5;241m=\u001b[39m _func_lookup[expr\u001b[38;5;241m.\u001b[39mfunc]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Y'"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "import torch\n",
    "from sympytorch import SymPyModule\n",
    "\n",
    "# Step 1: Define symbols\n",
    "X, Y, Z = sp.symbols('X Y Z')\n",
    "\n",
    "# Step 2: Define the SCM\n",
    "expr_Y = 2*X + 3\n",
    "expr_Z = X**2 + Y\n",
    "\n",
    "# Step 3: Compile expressions to PyTorch functions\n",
    "# For each symbolic expression, create a SymPyModule\n",
    "sympy_mod = SymPyModule(expressions=[Y, expr_Y, Z, expr_Z])\n",
    "#sympy_Y = SymPyModule(expressions=[Y, expr_Y])\n",
    "#sympy_Z = SymPyModule(expressions=[Z, expr_Z])\n",
    "\n",
    "# Step 4: Convert inputs to PyTorch tensors and evaluate\n",
    "# For instance, using a tensor input for X\n",
    "X_tensor = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Calculate Y using the compiled function\n",
    "Y_tensor = sympy_Y(X=X_tensor)\n",
    "print(\"Computed Y:\", Y_tensor)\n",
    "\n",
    "# Calculate Z using the compiled function, substituting Y\n",
    "Z_tensor = sympy_Z(X=X_tensor, Y=Y_tensor)\n",
    "print(\"Computed Z:\", Z_tensor)\n",
    "\n",
    "# You can also perform gradient computations if required\n",
    "Z_tensor.sum().backward()\n",
    "print(\"Gradient of X:\", X_tensor.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.1.1 (20240910.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"609pt\" height=\"381pt\"\n",
       " viewBox=\"0.00 0.00 608.56 380.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 376.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-376.5 604.56,-376.5 604.56,4 -4,4\"/>\n",
       "<!-- epsilon_X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>epsilon_X</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"258.79\" cy=\"-294.25\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.79\" y=\"-289.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_X</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"258.79\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.79\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- epsilon_X&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>epsilon_X&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M258.79,-275.95C258.79,-254.45 258.79,-217.43 258.79,-191.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.29,-191.88 258.79,-181.88 255.29,-191.88 262.29,-191.88\"/>\n",
       "</g>\n",
       "<!-- epsilon_Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>epsilon_Y</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"48.79\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"48.79\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Y</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"183.79\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- epsilon_Y&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>epsilon_Y&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M76.11,-146.83C98.43,-135.26 129.95,-118.92 153.13,-106.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.52,-110.12 161.78,-102.41 151.3,-103.91 154.52,-110.12\"/>\n",
       "</g>\n",
       "<!-- epsilon_Z -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>epsilon_Z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"324.79\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Z</text>\n",
       "</g>\n",
       "<!-- Z -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>Z</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"324.79\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.79\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Z</text>\n",
       "</g>\n",
       "<!-- epsilon_Z&#45;&gt;Z -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>epsilon_Z&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M324.79,-71.7C324.79,-64.41 324.79,-55.73 324.79,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"328.29,-47.62 324.79,-37.62 321.29,-47.62 328.29,-47.62\"/>\n",
       "</g>\n",
       "<!-- beta_X_Y -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>beta_X_Y</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"164.79\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"164.79\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Y</text>\n",
       "</g>\n",
       "<!-- beta_X_Y&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>beta_X_Y&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.49,-143.7C171.51,-136.24 173.93,-127.32 176.2,-118.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"179.51,-120.13 178.75,-109.57 172.76,-118.3 179.51,-120.13\"/>\n",
       "</g>\n",
       "<!-- beta_X_Z -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>beta_X_Z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"438.79\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"438.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Z</text>\n",
       "</g>\n",
       "<!-- beta_X_Z&#45;&gt;Z -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>beta_X_Z&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M414.62,-74.15C396.78,-63.2 372.43,-48.25 353.58,-36.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.67,-33.85 345.32,-31.6 352.01,-39.82 355.67,-33.85\"/>\n",
       "</g>\n",
       "<!-- beta_Y_Z -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>beta_Y_Z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"552.79\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"552.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_Y_Z</text>\n",
       "</g>\n",
       "<!-- beta_Y_Z&#45;&gt;Z -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>beta_Y_Z&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M516.67,-77.91C473.76,-64.74 402.67,-42.91 360.12,-29.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.22,-26.52 350.63,-26.93 359.16,-33.21 361.22,-26.52\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.62,-146.83C233.14,-137.06 219.02,-123.88 207.13,-112.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"209.75,-110.44 200.05,-106.18 204.98,-115.56 209.75,-110.44\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Z -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>X&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M257.05,-143.62C255.95,-124.92 256.46,-94.81 267.79,-72 274.42,-58.67 285.89,-47 296.82,-38.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.77,-40.95 304.55,-32.07 294.5,-35.4 298.77,-40.95\"/>\n",
       "</g>\n",
       "<!-- Y&#45;&gt;Z -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Y&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M204.9,-78.52C228.37,-66.87 266.51,-47.94 293.46,-34.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"294.78,-37.81 302.18,-30.22 291.67,-31.54 294.78,-37.81\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-355.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_X ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-338.7\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Y ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-322.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-305.7\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Y ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-289.2\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-272.7\" font-family=\"Times,serif\" font-size=\"14.00\">beta_Y_Z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-256.2\" font-family=\"Times,serif\" font-size=\"14.00\">X ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-239.7\" font-family=\"Times,serif\" font-size=\"14.00\">Y ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-223.2\" font-family=\"Times,serif\" font-size=\"14.00\">Z ~ Deterministic</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x128c84350>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compile_lscm_to_pyro(DAG: nx.DiGraph) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Compiles a Linear Structural Causal Model (LSCM) represented as a directed acyclic graph (DAG) into a Pyro model.\n",
    "    Parameters:\n",
    "    DAG (nx.DiGraph): A directed acyclic graph where nodes represent variables and edges represent causal relationships.\n",
    "                      Each node should have an 'expression' attribute containing a sympy expression for the variable.\n",
    "    Returns:\n",
    "    nx.DiGraph: The input DAG with additional attributes for each node:\n",
    "                - 'pyro_deterministic': The deterministic Pyro value for the node, computed based on the LSCM.\n",
    "    \"\"\"\n",
    "    symbols = list(DAG.nodes)\n",
    "    expressions = nx.get_node_attributes(DAG, 'expression')\n",
    "    \n",
    "    sympy_modules = {symbol: SymPyModule(expressions=[expressions[symbol]]) for symbol in symbols}\n",
    "    \n",
    "    epsilon_samples = {symbol: pyro.sample(f'epsilon_{symbol}', dist.Normal(0, 1)) for symbol in symbols}\n",
    "    beta_samples = {}\n",
    "    for parent, child in DAG.edges:\n",
    "        beta_samples[(parent, child)] = pyro.sample(f'beta_{parent}_{child}', dist.Normal(0, 1))\n",
    "        DAG.edges[parent, child]['beta'] = beta_samples[(parent, child)]\n",
    "    \n",
    "    pyro_deterministic_values = {}\n",
    "    for symbol in symbols:\n",
    "        input_params = {f'epsilon_{symbol}': epsilon_samples[symbol]}\n",
    "        for parent in DAG.predecessors(symbol):\n",
    "            input_params[parent.name] = pyro_deterministic_values[parent]\n",
    "            input_params[f'beta_{parent}_{symbol}'] = DAG.edges[parent, symbol]['beta']\n",
    "        pyro_deterministic_values[symbol] = pyro.deterministic(symbol.name, sympy_modules[symbol](**input_params))\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        DAG.nodes[symbol]['pyro_deterministic'] = pyro_deterministic_values[symbol]\n",
    "    \n",
    "    return DAG\n",
    "\n",
    "# Define the symbols and expressions\n",
    "X, Y, Z = sp.symbols('X Y Z')\n",
    "beta_XY, beta_YZ, beta_XZ = sp.symbols('beta_X_Y beta_Y_Z beta_X_Z')\n",
    "epsilon_X, epsilon_Y, epsilon_Z = sp.symbols('epsilon_X epsilon_Y epsilon_Z')\n",
    "\n",
    "# Create the DAG\n",
    "G = nx.DiGraph()\n",
    "G.add_node(X, expression=epsilon_X)\n",
    "G.add_node(Y, expression=beta_XY * X + epsilon_Y)\n",
    "G.add_node(Z, expression=beta_YZ * Y + epsilon_Z + beta_XZ * X + epsilon_Z)\n",
    "G.add_edges_from([(X, Y), (Y, Z), (X, Z)])\n",
    "\n",
    "# Compile the LSCM to Pyro\n",
    "DAG_with_deterministic = compile_lscm_to_pyro(G)\n",
    "\n",
    "\n",
    "# Visualize the model\n",
    "pyro.render_model(compile_lscm_to_pyro, model_args=(G,), render_distributions=True, render_deterministic=True, filename=\"LSCM_graph.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyciemss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
