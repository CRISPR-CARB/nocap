{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probablistic linear models using Pyro\n",
    "August George, 2024, PNNL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "$y_i = m_i*x_i + b_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoNormal\n",
    "\n",
    "\n",
    "pyro.set_rng_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the data\n",
    "true_intercept = 1\n",
    "true_slope = 2\n",
    "num_data_points = 100  \n",
    "X_values = torch.linspace(0, 1, num_data_points)\n",
    "Y_values = true_intercept + true_slope * X_values \n",
    "Y_obs_values = Y_values + torch.randn(num_data_points) \n",
    "\n",
    "\n",
    "plt.scatter(X_values, Y_obs_values, label=r'$Y_{obs} = Y_{true} + \\epsilon$, $\\epsilon \\sim \\text{Norm}(0,1)$')\n",
    "plt.plot(X_values, Y_values, color='red', label=r'$Y_{true}$')\n",
    "plt.ylabel('Y')\n",
    "plt.xlabel('X')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian inference using NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(X_values, Y_values):\n",
    "    intercept_prior = pyro.sample('intercept', dist.Normal(0, 10))\n",
    "    slope_prior = pyro.sample('slope', dist.Normal(0, 10))\n",
    "    noise_std_prior = pyro.sample('noise_std', dist.LogNormal(0, 1)) \n",
    "    mean_prediction = intercept_prior + slope_prior * X_values\n",
    "    with pyro.plate('data', len(X_values)):\n",
    "        pyro.sample('observations', dist.Normal(mean_prediction, noise_std_prior), obs=Y_values)\n",
    "\n",
    "# MCMC inference\n",
    "nuts_kernel = NUTS(linear_model)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(X_values, Y_obs_values)\n",
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_samples = posterior_samples[\"intercept\"]\n",
    "slope_samples = posterior_samples[\"slope\"]\n",
    "noise_std_samples = posterior_samples[\"noise_std\"]\n",
    "prior_intercept_samples = dist.Normal(0, 10).sample([1000])\n",
    "prior_slope_samples = dist.Normal(0, 10).sample([1000])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.kdeplot(prior_intercept_samples.numpy(), fill=True, color='blue', label='Prior Intercept', ax=axs[0])\n",
    "sns.kdeplot(intercept_samples.numpy(), fill=True, color='orange', label='Posterior Intercept', ax=axs[0])\n",
    "axs[0].set_title('Prior and Posterior Distribution of Intercept')\n",
    "axs[0].set_xlabel('Intercept')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "sns.kdeplot(prior_slope_samples.numpy(), fill=True, color='green', label='Prior Slope', ax=axs[1])\n",
    "sns.kdeplot(slope_samples.numpy(), fill=True, color='red', label='Posterior Slope', ax=axs[1])\n",
    "axs[1].set_title('Prior and Posterior Distribution of Slope')\n",
    "axs[1].set_xlabel('Slope')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "az.plot_trace({\"intercept\": intercept_samples, \"slope\": slope_samples})\n",
    "plt.show()\n",
    "\n",
    "intercept_mean = intercept_samples.mean().item()\n",
    "intercept_std = intercept_samples.std().item()\n",
    "slope_mean = slope_samples.mean().item()\n",
    "slope_std = slope_samples.std().item()\n",
    "noise_std_mean = noise_std_samples.mean().item()\n",
    "noise_std_std = noise_std_samples.std().item()\n",
    "\n",
    "display(f\"MCMC intercept_mean = {intercept_mean}, intercept_std = {intercept_std}\")\n",
    "display(f\"MCMC SVI slope_mean = {slope_mean}, slope_std = {slope_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_guide(X_values, Y_values):\n",
    "    intercept_loc = pyro.param('intercept_loc', torch.tensor(0.0))\n",
    "    intercept_scale = pyro.param('intercept_scale', torch.tensor(1.0), constraint=torch.distributions.constraints.positive)\n",
    "    slope_loc = pyro.param('slope_loc', torch.tensor(0.0))\n",
    "    slope_scale = pyro.param('slope_scale', torch.tensor(1.0), constraint=torch.distributions.constraints.positive)\n",
    "    noise_std_loc = pyro.param('noise_std_loc', torch.tensor(0.0))\n",
    "    noise_std_scale = pyro.param('noise_std_scale', torch.tensor(1.0), constraint=torch.distributions.constraints.positive)\n",
    "    pyro.sample('intercept', dist.Normal(intercept_loc, intercept_scale))\n",
    "    pyro.sample('slope', dist.Normal(slope_loc, slope_scale))\n",
    "    pyro.sample('noise_std', dist.LogNormal(noise_std_loc, noise_std_scale))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam({\"lr\": 0.01})\n",
    "svi_manual = SVI(linear_model, linear_model_guide, optimizer, loss=Trace_ELBO())\n",
    "num_iterations = 1000\n",
    "elbo_values = []  \n",
    "for step in range(num_iterations):\n",
    "    loss = svi_manual.step(X_values, Y_values)\n",
    "    elbo_values.append(loss)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Manual SVI Step {step} : loss = {loss}\")\n",
    "\n",
    "intercept_loc = pyro.param('intercept_loc').item()\n",
    "intercept_scale = pyro.param('intercept_scale').item()\n",
    "slope_loc = pyro.param('slope_loc').item()\n",
    "slope_scale = pyro.param('slope_scale').item()\n",
    "noise_std_loc = torch.tensor(pyro.param('noise_std_loc'))  # Convert to tensor\n",
    "noise_std_scale = torch.tensor(pyro.param('noise_std_scale'))  \n",
    "noise_std_exp = torch.exp(noise_std_loc).item()\n",
    "\n",
    "prior_intercept_samples = dist.Normal(0, 10).sample([1000]).numpy()\n",
    "prior_slope_samples = dist.Normal(0, 10).sample([1000]).numpy()\n",
    "intercept_samples = dist.Normal(intercept_loc, intercept_scale).sample([1000]).numpy()\n",
    "slope_samples = dist.Normal(slope_loc, slope_scale).sample([1000]).numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(elbo_values)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('ELBO (loss)')\n",
    "plt.title('ELBO Plot for Manual SVI')\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 5))\n",
    "sns.kdeplot(prior_intercept_samples, fill=True, color='blue', label='Prior Intercept', ax=axs[0])\n",
    "sns.kdeplot(intercept_samples, fill=True, color='orange', label='Posterior Intercept', ax=axs[0])\n",
    "axs[0].set_title('Prior and Posterior Distribution of Intercept')\n",
    "axs[0].set_xlabel('Intercept')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_slope_samples, fill=True, color='green', label='Prior Slope', ax=axs[1])\n",
    "sns.kdeplot(slope_samples, fill=True, color='orange', label='Posterior Slope', ax=axs[1])\n",
    "axs[1].set_title('Prior and Posterior Distribution of Slope')\n",
    "axs[1].set_xlabel('Slope')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "display(f\"Manual SVI intercept_mean = {intercept_loc}, intercept_std = {intercept_scale}\")\n",
    "display(f\"Manual SVI slope_mean = {slope_loc}, slope_std = {slope_scale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational inference using an autoguide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_guide = AutoNormal(linear_model)\n",
    "optimizer = optim.Adam({\"lr\": 0.01})\n",
    "svi = SVI(linear_model, auto_guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "num_iterations = 1000\n",
    "elbo_values = []  \n",
    "for step in range(num_iterations):\n",
    "    loss = svi.step(X_values, Y_values)\n",
    "    elbo_values.append(loss)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step} : loss = {loss}\")\n",
    "\n",
    "# get samples\n",
    "prior_intercept_samples = dist.Normal(0, 10).sample([1000]).numpy()\n",
    "prior_slope_samples = dist.Normal(0, 10).sample([1000]).numpy()\n",
    "posterior_samples = [auto_guide() for _ in range(1000)]\n",
    "posterior_samples = {k: torch.stack([s[k] for s in posterior_samples]) for k in posterior_samples[0]}\n",
    "intercept_samples = posterior_samples['intercept'].detach().numpy()\n",
    "slope_samples = posterior_samples['slope'].detach().numpy()\n",
    "noise_std_samples = torch.exp(posterior_samples['noise_std']).detach().numpy()\n",
    "intercept_mean = intercept_samples.mean()\n",
    "intercept_std = intercept_samples.std()\n",
    "slope_mean = slope_samples.mean()\n",
    "slope_std = slope_samples.std()\n",
    "noise_std_mean = noise_std_samples.mean()\n",
    "noise_std_std = noise_std_samples.std()\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(elbo_values)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('ELBO (loss)')\n",
    "plt.title('ELBO Plot for Auto SVI')\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 5))\n",
    "sns.kdeplot(prior_intercept_samples, fill=True, color='blue', label='Prior Intercept', ax=axs[0])\n",
    "sns.kdeplot(intercept_samples, fill=True, color='orange', label='Posterior Intercept', ax=axs[0])\n",
    "axs[0].set_title('Prior and Posterior Distribution of Intercept')\n",
    "axs[0].set_xlabel('Intercept')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_slope_samples, fill=True, color='green', label='Prior Slope', ax=axs[1])\n",
    "sns.kdeplot(slope_samples, fill=True, color='orange', label='Posterior Slope', ax=axs[1])\n",
    "axs[1].set_title('Prior and Posterior Distribution of Slope')\n",
    "axs[1].set_xlabel('Slope')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(f\"Auto SVI intercept_mean = {intercept_mean}, intercept_std = {intercept_std}\")\n",
    "display(f\"Auto SVI slope_mean = {slope_mean}, slope_std = {slope_std}\")\n",
    "display(f\"Auto SVI noise_std_mean = {noise_std_mean}, noise_std_std = {noise_std_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear structural causal model from gene regulatory network\n",
    "\n",
    "A --> B\n",
    "\n",
    "B --> C\n",
    "\n",
    "D --| B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples\n",
    "num_samples = 100\n",
    "\n",
    "# Ground truth parameters\n",
    "true_beta_A_B = 2.0\n",
    "true_beta_D_B = -1.0\n",
    "true_beta_B_C = 1.5\n",
    "\n",
    "# Generate synthetic data\n",
    "epsilon_A = torch.normal(0, 1, (num_samples,))\n",
    "epsilon_B = torch.normal(0, 1, (num_samples,))\n",
    "epsilon_C = torch.normal(0, 1, (num_samples,))\n",
    "epsilon_D = torch.normal(0, 1, (num_samples,))\n",
    "\n",
    "A = epsilon_A\n",
    "D = epsilon_D\n",
    "B = true_beta_A_B * A + true_beta_D_B * D + epsilon_B\n",
    "C = true_beta_B_C * B + epsilon_C\n",
    "\n",
    "\n",
    "# Print first few samples for inspection\n",
    "display('Synthetic Data (first 5 samples):')\n",
    "display('A =', A[:5])\n",
    "display('B =', B[:5])\n",
    "display('C =', C[:5])\n",
    "display('D =', D[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_network_model(A, B, C, D, num_samples):\n",
    "    # Priors for parameters\n",
    "    beta_A_B = pyro.sample('beta_A_B', dist.Normal(0, 1))\n",
    "    beta_D_B = pyro.sample('beta_D_B', dist.Normal(0, 1))\n",
    "    beta_B_C = pyro.sample('beta_B_C', dist.Normal(0, 1))\n",
    "    \n",
    "    # Priors for epsilon (noise terms)\n",
    "    epsilon_A = pyro.sample('epsilon_A', dist.Normal(0, 1).expand([num_samples]).to_event(1))\n",
    "    epsilon_B = pyro.sample('epsilon_B', dist.Normal(0, 1).expand([num_samples]).to_event(1))\n",
    "    epsilon_C = pyro.sample('epsilon_C', dist.Normal(0, 1).expand([num_samples]).to_event(1))\n",
    "    epsilon_D = pyro.sample('epsilon_D', dist.Normal(0, 1).expand([num_samples]).to_event(1))\n",
    "    \n",
    "    # Structural equations with uncertainty (noise terms)\n",
    "\n",
    "    # use determinstic to represent \n",
    "    A_model = epsilon_A\n",
    "    D_model = epsilon_D\n",
    "    B_model = beta_A_B * A_model + beta_D_B * D_model + epsilon_B\n",
    "    C_model = beta_B_C * B_model + epsilon_C\n",
    "    \n",
    "    \n",
    "    # Define likelihoods for observed (real) data\n",
    "    with pyro.plate('data', num_samples):\n",
    "        pyro.sample('obs_A', dist.Normal(A_model, 1), obs=A)\n",
    "        pyro.sample('obs_B', dist.Normal(B_model, 1), obs=B)\n",
    "        pyro.sample('obs_C', dist.Normal(C_model, 1), obs=C)\n",
    "        pyro.sample('obs_D', dist.Normal(D_model, 1), obs=D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.render_model(gene_network_model, model_args=(A,  B, C, D, num_samples), render_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.infer.mcmc as mcmc\n",
    "import pyro.infer.mcmc.api as mcmc_api\n",
    "\n",
    "pyro.set_rng_seed(42)\n",
    "\n",
    "# Perform MCMC inference\n",
    "pyro.clear_param_store()\n",
    "kernel = mcmc_api.NUTS(lambda A,  B, C, D: gene_network_model(A,  B, C, D, num_samples), adapt_step_size=True)\n",
    "mcmc_run = mcmc_api.MCMC(kernel, num_samples=1000, warmup_steps=200, num_chains=1)\n",
    "mcmc_run.run(A, B, C, D)\n",
    "\n",
    "# Extract samples\n",
    "mcmc_samples = mcmc_run.get_samples()\n",
    "\n",
    "# Prior samples for comparison\n",
    "prior_sample_size = 1000\n",
    "prior_beta_A_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_D_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_B_C = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "\n",
    "# Posterior samples\n",
    "posterior_beta_A_B = mcmc_samples['beta_A_B'].detach().numpy()\n",
    "posterior_beta_D_B = mcmc_samples['beta_D_B'].detach().numpy()\n",
    "posterior_beta_B_C = mcmc_samples['beta_B_C'].detach().numpy()\n",
    "\n",
    "# Plot KDEs\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.kdeplot(prior_beta_A_B, fill=True, color='blue', label='Prior Beta_A_B', ax=axs[0])\n",
    "sns.kdeplot(posterior_beta_A_B, fill=True, color='orange', label='Posterior Beta_A_B', ax=axs[0])\n",
    "axs[0].axvline(true_beta_A_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_A_B')\n",
    "axs[0].set_title('Prior and Posterior Distribution of Beta_A_B')\n",
    "axs[0].set_xlabel('Beta_A_B')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_D_B, fill=True, color='blue', label='Prior Beta_D_B', ax=axs[1])\n",
    "sns.kdeplot(posterior_beta_D_B, fill=True, color='orange', label='Posterior Beta_D_B', ax=axs[1])\n",
    "axs[1].axvline(true_beta_D_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_D_B')\n",
    "axs[1].set_title('Prior and Posterior Distribution of Beta_D_B')\n",
    "axs[1].set_xlabel('Beta_D_B')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_B_C, fill=True, color='blue', label='Prior Beta_B_C', ax=axs[2])\n",
    "sns.kdeplot(posterior_beta_B_C, fill=True, color='orange', label='Posterior Beta_B_C', ax=axs[2])\n",
    "axs[2].axvline(true_beta_B_C, color='black', linestyle='dashed', linewidth=1, label='True Beta_B_C')\n",
    "axs[2].set_title('Prior and Posterior Distribution of Beta_B_C')\n",
    "axs[2].set_xlabel('Beta_B_C')\n",
    "axs[2].set_ylabel('Density')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the guide\n",
    "guide = AutoNormal(gene_network_model)\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
    "\n",
    "# Set up the SVI object\n",
    "svi = SVI(gene_network_model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "# Number of training steps\n",
    "num_steps = 10000\n",
    "\n",
    "# Run SVI\n",
    "pyro.clear_param_store()\n",
    "for step in range(num_steps):\n",
    "    svi.step(A,  B, C, D, num_samples)\n",
    "    if step % 500 == 0:\n",
    "        elbo = svi.evaluate_loss(A, B, C,  D, num_samples)\n",
    "        print(f'Step {step} - ELBO: {elbo}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "\n",
    "# Use Predictive to get posterior samples\n",
    "predictive = Predictive(guide, num_samples=1000)\n",
    "posterior_samples = predictive(A,  B, C, D, num_samples)\n",
    "posterior_beta_A_B = posterior_samples['beta_A_B'].detach().numpy()\n",
    "posterior_beta_D_B = posterior_samples['beta_D_B'].detach().numpy()\n",
    "posterior_beta_B_C = posterior_samples['beta_B_C'].detach().numpy()\n",
    "\n",
    "# Prior samples for comparison\n",
    "prior_sample_size = 1000\n",
    "prior_beta_A_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_D_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_B_C = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "\n",
    "# Plot KDEs\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.kdeplot(prior_beta_A_B, fill=True, color='blue', label='Prior Beta_A_B', ax=axs[0])\n",
    "sns.kdeplot(posterior_beta_A_B, fill=True, color='orange', label='Posterior Beta_A_B', ax=axs[0])\n",
    "axs[0].axvline(true_beta_A_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_A_B')\n",
    "axs[0].set_title('Prior and Posterior Distribution of Beta_A_B')\n",
    "axs[0].set_xlabel('Beta_A_B')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_D_B, fill=True, color='blue', label='Prior Beta_D_B', ax=axs[1])\n",
    "sns.kdeplot(posterior_beta_D_B, fill=True, color='orange', label='Posterior Beta_D_B', ax=axs[1])\n",
    "axs[1].axvline(true_beta_D_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_D_B')\n",
    "axs[1].set_title('Prior and Posterior Distribution of Beta_D_B')\n",
    "axs[1].set_xlabel('Beta_D_B')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_B_C, fill=True, color='blue', label='Prior Beta_B_C', ax=axs[2])\n",
    "sns.kdeplot(posterior_beta_B_C, fill=True, color='orange', label='Posterior Beta_B_C', ax=axs[2])\n",
    "axs[2].axvline(true_beta_B_C, color='black', linestyle='dashed', linewidth=1, label='True Beta_B_C')\n",
    "axs[2].set_title('Prior and Posterior Distribution of Beta_B_C')\n",
    "axs[2].set_xlabel('Beta_B_C')\n",
    "axs[2].set_ylabel('Density')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVI with multinormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from pyro.infer.autoguide import AutoNormal, AutoMultivariateNormal, AutoNormalizingFlow, AutoLowRankMultivariateNormal\n",
    "from pyro.distributions.transforms import AffineAutoregressive\n",
    "import pyro.optim  # Ensure that Pyro's optim module is imported\n",
    "from pyro.optim import Adam, PyroLRScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "pyro.set_rng_seed(40)\n",
    "\n",
    "# Define the guide\n",
    "guide = AutoMultivariateNormal(gene_network_model)\n",
    "#guide = AutoNormal(gene_network_model)\n",
    "\n",
    "\n",
    "# # Set up the optimizer\n",
    "# adam_params = {\"lr\": 0.001}\n",
    "# scheduler_params = {\n",
    "#     \"optimizer\": torch.optim.Adam,\n",
    "#     \"optim_args\": adam_params,\n",
    "#     \"step_size\": 5000,  \n",
    "#     \"gamma\": 0.3  \n",
    "# }\n",
    "# scheduler = pyro.optim.StepLR(scheduler_params)\n",
    "\n",
    "scheduler =  Adam({\"lr\": 0.001})  # Use a constant learning rate\n",
    "\n",
    "# Set up the SVI object\n",
    "svi = SVI(gene_network_model, guide, scheduler, loss=Trace_ELBO())\n",
    "\n",
    "# Number of training steps\n",
    "num_steps = 2000\n",
    "\n",
    "# Run SVI with progress bar\n",
    "pyro.clear_param_store()\n",
    "elbos = []\n",
    "with tqdm(total=num_steps, desc=\"SVI Training Progress\") as pbar:\n",
    "    for step in range(num_steps):\n",
    "        elbo = svi.step(A,B, C,  D, num_samples)\n",
    "        elbos.append(elbo)\n",
    "        if step % 100 == 0:\n",
    "            pbar.set_postfix(ELBO=elbo)\n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "# Plot ELBOs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(elbos)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('ELBO')\n",
    "plt.title('ELBO over Time')\n",
    "plt.show()\n",
    "\n",
    "# Posterior predictive checks\n",
    "predictive = Predictive(guide, num_samples=1000)\n",
    "posterior_samples = predictive(A=A, B=B, C=C, D=D, num_samples=num_samples)\n",
    "\n",
    "posterior_beta_A_B = posterior_samples['beta_A_B'].detach().numpy().flatten()\n",
    "posterior_beta_D_B = posterior_samples['beta_D_B'].detach().numpy().flatten()\n",
    "posterior_beta_B_C = posterior_samples['beta_B_C'].detach().numpy().flatten()\n",
    "\n",
    "# Prior samples for comparison\n",
    "prior_sample_size = 1000\n",
    "prior_beta_A_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_D_B = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "prior_beta_B_C = dist.Normal(0, 1).sample([prior_sample_size]).detach().numpy()\n",
    "\n",
    "# Plot KDEs\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.kdeplot(prior_beta_A_B, fill=True, color='blue', label='Prior Beta_A_B', ax=axs[0])\n",
    "sns.kdeplot(posterior_beta_A_B, fill=True, color='orange', label='Posterior Beta_A_B', ax=axs[0])\n",
    "axs[0].axvline(true_beta_A_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_A_B')\n",
    "axs[0].set_title('Prior and Posterior Distribution of Beta_A_B')\n",
    "axs[0].set_xlabel('Beta_A_B')\n",
    "axs[0].set_ylabel('Density')\n",
    "axs[0].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_D_B, fill=True, color='blue', label='Prior Beta_D_B', ax=axs[1])\n",
    "sns.kdeplot(posterior_beta_D_B, fill=True, color='orange', label='Posterior Beta_D_B', ax=axs[1])\n",
    "axs[1].axvline(true_beta_D_B, color='black', linestyle='dashed', linewidth=1, label='True Beta_D_B')\n",
    "axs[1].set_title('Prior and Posterior Distribution of Beta_D_B')\n",
    "axs[1].set_xlabel('Beta_D_B')\n",
    "axs[1].set_ylabel('Density')\n",
    "axs[1].legend()\n",
    "\n",
    "sns.kdeplot(prior_beta_B_C, fill=True, color='blue', label='Prior Beta_B_C', ax=axs[2])\n",
    "sns.kdeplot(posterior_beta_B_C, fill=True, color='orange', label='Posterior Beta_B_C', ax=axs[2])\n",
    "axs[2].axvline(true_beta_B_C, color='black', linestyle='dashed', linewidth=1, label='True Beta_B_C')\n",
    "axs[2].set_title('Prior and Posterior Distribution of Beta_B_C')\n",
    "axs[2].set_xlabel('Beta_B_C')\n",
    "axs[2].set_ylabel('Density')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding technical noise to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a pyro module\n",
    "\n",
    "Goal: use a simple linear model to validate a probablistic model for biological and observational processes.\n",
    "\n",
    "### The biological process model\n",
    "$A$ regulates $B$ (A-->B), which is represented with a linear model: $A = \\epsilon_A$ and $B = \\beta_{AB}A + \\epsilon_B$.\n",
    "\n",
    "$\\epsilon_A$ and $\\epsilon_B$ represent biological noise and are sampled from Normal(0,1).\n",
    "\n",
    "$\\beta_{AB}$ represents the strength of the regulation between $A$ and $B$.\n",
    "\n",
    "### The observational model\n",
    "Our observations are not from the biological model directly, but include technical noise from the experiment. \n",
    "\n",
    "The observed gene expression values are a function of the biological and observational/technical processes: \n",
    "$A_{obs} = f(A, \\theta_{bio}^A, \\theta_{obs}^A)$ and \n",
    "$B_{obs} = f(B, \\theta_{bio}^B, \\theta_{obs}^B)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from pyro.nn import PyroModule, PyroSample, PyroParam\n",
    "\n",
    "class BiologicalProcess(PyroModule):\n",
    "    def __init__(self, num_samples=100, beta_AB_true=2):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.register_buffer('beta_AB_true',torch.tensor(beta_AB_true) )\n",
    "\n",
    "    @PyroSample\n",
    "    def epsilon_A(self):\n",
    "        return dist.Normal(0, 1).expand([self.num_samples]).to_event(1)\n",
    "\n",
    "    @PyroSample\n",
    "    def epsilon_B(self):\n",
    "        return dist.Normal(0, 1).expand([self.num_samples]).to_event(1)\n",
    "\n",
    "    @PyroSample\n",
    "    def beta_AB(self):\n",
    "        return dist.Normal(0, 1).expand([self.num_samples]).to_event(1)\n",
    "\n",
    "    def forward(self):\n",
    "        A_bio = pyro.deterministic('A_bio', torch.clamp(self.epsilon_A, min=0))\n",
    "        B_bio = pyro.deterministic('B_bio', torch.clamp(self.beta_AB * A_bio + self.epsilon_B, min=0))\n",
    "        return A_bio, B_bio\n",
    "\n",
    "\n",
    "class TechnicalNoiseProcess(PyroModule):\n",
    "    def __init__(self, biological_model, k=1, q=0.5, epsilon=1e-8):\n",
    "        super().__init__()\n",
    "        self.biological_model = biological_model\n",
    "        self.register_buffer(\"k\", torch.tensor(k))  \n",
    "        self.register_buffer(\"q\", torch.tensor(q))  \n",
    "        self.register_buffer(\"eps\", torch.tensor(epsilon))  \n",
    "\n",
    "    def forward(self, A_obs=torch.as_tensor(1.0), B_obs=torch.as_tensor(1.0), return_generated=False):\n",
    "        A_bio, B_bio = self.biological_model()\n",
    "\n",
    "        A_obs_mask = ~A_obs.isnan()\n",
    "        B_obs_mask = ~B_obs.isnan()\n",
    "\n",
    "        with pyro.plate('data', self.biological_model.num_samples):\n",
    "\n",
    "            A_UMI_obs = pyro.sample('A_UMI_obs', dist.Poisson(A_bio+self.eps), obs=A_obs, obs_mask=A_obs_mask)\n",
    "            B_UMI_obs = pyro.sample('B_UMI_obs', dist.Poisson(B_bio+self.eps), obs=B_obs, obs_mask=B_obs_mask)\n",
    "\n",
    "        if return_generated:\n",
    "            return A_UMI_obs, B_UMI_obs\n",
    "\n",
    "# Instantiate and run the technical noise process model with the biological model\n",
    "biological_model = BiologicalProcess(num_samples=100)\n",
    "pyro.render_model(biological_model, render_distributions=True, render_deterministic=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_noise_process = TechnicalNoiseProcess(biological_model)\n",
    "pyro.render_model(technical_noise_process, render_distributions=True, render_deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples \n",
    "beta_AB_true = biological_model.beta_AB_true.detach().cpu().numpy()\n",
    "A_obs_tensor, B_obs_tensor = technical_noise_process(return_generated=True)\n",
    "A_obs = A_obs_tensor.detach()\n",
    "B_obs = B_obs_tensor.detach()\n",
    "\n",
    "display(A_obs[:100])\n",
    "display(B_obs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.poutine as poutine\n",
    "from pyro.infer import SVI, TraceEnum_ELBO\n",
    "from pyro.infer.autoguide import AutoMultivariateNormal\n",
    "\n",
    "beta_AB_true = biological_model.beta_AB_true.detach().cpu().numpy()\n",
    "A_obs_tensor, B_obs_tensor = technical_noise_process.forward(return_generated=True)\n",
    "A_obs = A_obs_tensor.detach()\n",
    "B_obs = B_obs_tensor.detach()\n",
    "\n",
    "display(f'True beta_AB: {beta_AB_true}')\n",
    "display(type(A_obs))\n",
    "\n",
    "\n",
    "# Define the model to be used for inference\n",
    "def model(A_obs, B_obs):\n",
    "    biological_model = BiologicalProcess(num_samples=100)\n",
    "    technical_model = TechnicalNoiseProcess(biological_model)\n",
    "    technical_model.forward(A_obs=A_obs, B_obs=B_obs)\n",
    "\n",
    "# Define a guide that allows enumeration of discrete variables\n",
    "guide = AutoMultivariateNormal(poutine.block(model, hide=['dropout_binary_indicator_A', 'dropout_binary_indicator_B']))\n",
    "\n",
    "# Use TraceEnum_ELBO to handle discrete enumeration\n",
    "optimizer = pyro.optim.Adam({\"lr\": 0.01})\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "\n",
    "svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "# Run SVI\n",
    "num_steps = 2000\n",
    "losses = []\n",
    "for step in range(num_steps):\n",
    "    loss = svi.step(A_obs, B_obs)\n",
    "    losses.append(loss)\n",
    "    if step % 500 == 0:\n",
    "        print(f\"Step {step} : loss = {loss}\")\n",
    "        \n",
    "# Plot the loss curve\n",
    "plt.plot(losses)\n",
    "plt.xlabel('SVI step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.show()\n",
    "\n",
    "# Extract learned parameters from the AutoGuide\n",
    "posterior_samples = guide.get_posterior().sample((1000,))\n",
    "\n",
    "# Generate prior samples for beta_AB\n",
    "prior_samples = dist.Normal(0, 1).sample((1000,)).numpy()\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(posterior_samples.flatten(), bins=30, density=True, alpha=0.6, color='k', label='Learned beta_AB posterior')\n",
    "plt.hist(prior_samples, bins=30, density=True, alpha=0.6, color='b', label='Prior beta_AB')\n",
    "plt.axvline(x=beta_AB_true, color='r', linestyle='--', label='True beta_AB')\n",
    "plt.xlabel('beta_AB')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Posterior and Prior Distribution of beta_AB')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generalized linear structural causal model \n",
    "\n",
    "$\\vec{y} = \\underset{n \\times n}\\Alpha\\vec{x} + \\vec{\\epsilon}$\n",
    "\n",
    "example $A\\rightarrow B$:\n",
    "\n",
    "\n",
    "$y_A = \\epsilon_A$\n",
    "\n",
    "$y_B = \\alpha_{AB}\\cdot A  + \\epsilon_B$\n",
    "\n",
    "$\\vec{y} = [y_A, y_B]$\n",
    "\n",
    "$\\underset{2\\times 2} \\Alpha = \\begin{bmatrix}0 & \\alpha_{AB} \\\\ 0&0 \\end{bmatrix}$\n",
    "\n",
    "$\\vec{\\epsilon} = [\\epsilon_A, \\epsilon_B]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "graph = nx.DiGraph()\n",
    "graph.add_edge('A', 'B')\n",
    "adj_matrix_dense = nx.adjacency_matrix(graph).toarray()\n",
    "adj_matrix_dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph (DiGraph)\n",
    "G = nx.DiGraph()\n",
    "G.add_edge(0, 1)\n",
    "G.add_edge(1, 2)\n",
    "G.add_edge(2, 0)\n",
    "G.add_edge(2, 3)\n",
    "\n",
    "# Plot the visual graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "nx.draw(G, with_labels=True, node_color='skyblue', node_size=2000, edge_color='k', font_size=15, font_color='black', font_weight='bold')\n",
    "plt.title('Graph Visualization')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Get the adjacency matrix as a dense NumPy array\n",
    "adj_matrix_dense = nx.adjacency_matrix(G).toarray()\n",
    "display(adj_matrix_dense)\n",
    "\n",
    "\n",
    "# Convert the dense NumPy array to a PyTorch sparse tensor\n",
    "adj_matrix_dense = torch.tensor(adj_matrix_dense, dtype=torch.float32)\n",
    "adj_matrix_sparse = adj_matrix_dense.to_sparse()\n",
    "display(adj_matrix_sparse)\n",
    "\n",
    "\n",
    "# Define a simple model using the sparse adjacency matrix\n",
    "def model(adj_matrix_sparse):\n",
    "    num_nodes = adj_matrix_sparse.size(0)\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if (adj_matrix_sparse._indices() == torch.tensor([[i], [j]])).all(dim=0).any():\n",
    "                # Sample from a distribution for nonzero elements\n",
    "                pyro.sample(f\"alpha_{i}_{j}\", dist.Normal(0, 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Trace the model execution\n",
    "trace = poutine.trace(model).get_trace(adj_matrix_sparse)\n",
    "\n",
    "# Print the trace\n",
    "for name, site in trace.nodes.items():\n",
    "    if site[\"type\"] == \"sample\":\n",
    "        print(f\"{name}: {site['value']}\")\n",
    "\n",
    "pyro.render_model(model, model_args=(adj_matrix_sparse,), render_distributions=True, render_deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adjacency matrix: tensor([[0, 1, 0, 1],\\n        [0, 0, 1, 0],\\n        [0, 0, 0, 0],\\n        [0, 0, 0, 0]])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"560pt\" height=\"414pt\"\n",
       " viewBox=\"0.00 0.00 560.05 413.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 409.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-409.5 556.05,-409.5 556.05,4 -4,4\"/>\n",
       "<!-- epsilon_A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>epsilon_A</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"256.28\" cy=\"-310.75\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.28\" y=\"-305.7\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_A</text>\n",
       "</g>\n",
       "<!-- A -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"256.28\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n",
       "</g>\n",
       "<!-- epsilon_A&#45;&gt;A -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>epsilon_A&#45;&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256.28,-292.34C256.28,-267.52 256.28,-221.65 256.28,-191.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.78,-191.9 256.28,-181.9 252.78,-191.9 259.78,-191.9\"/>\n",
       "</g>\n",
       "<!-- epsilon_B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>epsilon_B</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"48.28\" cy=\"-162\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"48.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_B</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"215.28\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.28\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n",
       "</g>\n",
       "<!-- epsilon_B&#45;&gt;B -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>epsilon_B&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M79.3,-148C108.62,-135.71 152.46,-117.33 182.38,-104.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"183.45,-108.14 191.32,-101.04 180.75,-101.68 183.45,-108.14\"/>\n",
       "</g>\n",
       "<!-- epsilon_C -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>epsilon_C</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"390.28\" cy=\"-90\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.28\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_C</text>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"390.28\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.28\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">C</text>\n",
       "</g>\n",
       "<!-- epsilon_C&#45;&gt;C -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>epsilon_C&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M390.28,-71.7C390.28,-64.41 390.28,-55.73 390.28,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"393.78,-47.62 390.28,-37.62 386.78,-47.62 393.78,-47.62\"/>\n",
       "</g>\n",
       "<!-- epsilon_D -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>epsilon_D</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"350.28\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"350.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_D</text>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"297.28\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.28\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">D</text>\n",
       "</g>\n",
       "<!-- epsilon_D&#45;&gt;D -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>epsilon_D&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M337.72,-144.41C331.2,-135.8 323.11,-125.11 315.88,-115.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"318.76,-113.58 309.94,-107.72 313.18,-117.8 318.76,-113.58\"/>\n",
       "</g>\n",
       "<!-- beta_A_B -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>beta_A_B</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"163.28\" cy=\"-162\" rx=\"48.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_A_B</text>\n",
       "</g>\n",
       "<!-- beta_A_B&#45;&gt;B -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>beta_A_B&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M175.6,-144.41C182,-135.8 189.94,-125.11 197.04,-115.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.7,-117.84 202.86,-107.73 194.08,-113.67 199.7,-117.84\"/>\n",
       "</g>\n",
       "<!-- beta_A_D -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>beta_A_D</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"466.28\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"466.28\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_A_D</text>\n",
       "</g>\n",
       "<!-- beta_A_D&#45;&gt;D -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>beta_A_D&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M432.98,-148.39C405.93,-137.99 366.9,-122.62 333.28,-108 331.78,-107.35 330.24,-106.67 328.69,-105.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"330.42,-102.92 319.88,-101.92 327.5,-109.28 330.42,-102.92\"/>\n",
       "</g>\n",
       "<!-- beta_B_C -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>beta_B_C</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"504.28\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"504.28\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_B_C</text>\n",
       "</g>\n",
       "<!-- beta_B_C&#45;&gt;C -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>beta_B_C&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M480.1,-74.15C462.26,-63.2 437.92,-48.25 419.07,-36.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"421.16,-33.85 410.8,-31.6 417.49,-39.82 421.16,-33.85\"/>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.77,-144.76C241.91,-136.46 235.87,-126.15 230.39,-116.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"233.58,-115.31 225.5,-108.45 227.54,-118.85 233.58,-115.31\"/>\n",
       "</g>\n",
       "<!-- A&#45;&gt;D -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>A&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.79,-144.76C270.65,-136.46 276.69,-126.15 282.17,-116.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"285.02,-118.85 287.06,-108.45 278.98,-115.31 285.02,-118.85\"/>\n",
       "</g>\n",
       "<!-- B&#45;&gt;C -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>B&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.16,-79.85C268.42,-67.74 321.99,-46.32 356.8,-32.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"358.01,-35.68 365.99,-28.72 355.41,-29.18 358.01,-35.68\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-388.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_A ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-371.7\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_B ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-355.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_C ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-338.7\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_D ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-322.2\" font-family=\"Times,serif\" font-size=\"14.00\">beta_A_B ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-305.7\" font-family=\"Times,serif\" font-size=\"14.00\">beta_A_D ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-289.2\" font-family=\"Times,serif\" font-size=\"14.00\">beta_B_C ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-272.7\" font-family=\"Times,serif\" font-size=\"14.00\">A ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-256.2\" font-family=\"Times,serif\" font-size=\"14.00\">B ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-239.7\" font-family=\"Times,serif\" font-size=\"14.00\">C ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"331.03\" y=\"-223.2\" font-family=\"Times,serif\" font-size=\"14.00\">D ~ Deterministic</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1612277d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "\n",
    "\n",
    "def linear_structural_causal_model(adjacency_matrix, node_names):    \n",
    "    # Initialize a dictionary to store the sampled values\n",
    "    state_variables = {}\n",
    "    \n",
    "    # Sample noise for each state variable\n",
    "    noise = {name: pyro.sample(f\"epsilon_{name}\", dist.Normal(0, 1)) for name in node_names}\n",
    "    \n",
    "    # Prior distributions for the beta parameters (relationship strengths)\n",
    "    beta = {f\"beta_{parent}_{child}\": pyro.sample(f\"beta_{parent}_{child}\", dist.Normal(0, 1)) \n",
    "            for i, parent in enumerate(node_names) for j, child in enumerate(node_names) if adjacency_matrix[i][j] == 1}\n",
    "    \n",
    "    # Calculate the values of state variables based on their parents\n",
    "    for j, child in enumerate(node_names):\n",
    "        parent_sum = 0.0\n",
    "        for i, parent in enumerate(node_names):\n",
    "            if adjacency_matrix[i][j] == 1:\n",
    "                parent_sum += beta[f\"beta_{parent}_{child}\"] * state_variables.get(parent, noise[parent])\n",
    "        state_variables[child] = pyro.deterministic(child, parent_sum + noise[child])\n",
    "    \n",
    "    return state_variables\n",
    "\n",
    "\n",
    "\n",
    "# Define the DAG using an adjacency matrix (A -> B -> C, A -> D)\n",
    "adj_matrix = torch.tensor([[0, 1, 0, 1],  # A\n",
    "                           [0, 0, 1, 0],  # B\n",
    "                           [0, 0, 0, 0],  # C\n",
    "                           [0, 0, 0, 0]]) # D\n",
    "\n",
    "display(f\"adjacency matrix: {adj_matrix}\")\n",
    "\n",
    "node_names = ['A', 'B', 'C', 'D']\n",
    "\n",
    "# Create a directed graph (DiGraph)\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([('A', 'B'), ('B', 'C'), ('A', 'D')])\n",
    "\n",
    "# Plot the visual graph\n",
    "plt.figure(figsize=(8, 6))\n",
    "nx.draw(G, with_labels=True, node_color='skyblue', node_size=2000, edge_color='k', font_size=15, font_color='black', font_weight='bold')\n",
    "plt.title('Graph Visualization')\n",
    "plt.show()\n",
    "\n",
    "# Generate the probabilistic model\n",
    "pyro.clear_param_store()  # Clear the parameter store\n",
    "model = lambda: linear_structural_causal_model(adj_matrix, node_names)\n",
    "\n",
    "# Visualize the model\n",
    "pyro.render_model(model, render_distributions=True, render_deterministic=True, filename=\"LSCM_graph.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[z, y, x]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import sympy as sy\n",
    "import sympytorch\n",
    "\n",
    "# # TODO: extra funcs argument in sympytorch.SymPyModule?\n",
    "# def solve_lscm(sympy_symbol_params, sympy_lscm):\n",
    "#     eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]   \n",
    "#     sympy_out = sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "    \n",
    "#     return sympy_out\n",
    "\n",
    "# solve_lscm(sympy_symbol_params, sympy_lscm)\n",
    "\n",
    "\n",
    "# Define the LSCM symbols and equations\n",
    "x, y, z, beta_xy, beta_yz, epsilon_x, epsilon_y, epsilon_z = sy.symbols('x y z beta_xy beta_yz epsilon_x epsilon_y epsilon_z')\n",
    "sympy_lscm = {\n",
    "    z: epsilon_z,\n",
    "    y: beta_yz * z + epsilon_y,\n",
    "    x: beta_xy * y + epsilon_x,\n",
    "}\n",
    "\n",
    "# networkx graph \n",
    "G = nx.DiGraph()\n",
    "G.add_edge(z, y)\n",
    "G.add_edge(y, x)\n",
    "sorted_nodes = list(nx.topological_sort(G))\n",
    "display(sorted_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[z, y, x]\n",
      "[epsilon_z, beta_yz*z + epsilon_y, beta_xy*y + epsilon_x]\n"
     ]
    }
   ],
   "source": [
    "substituted_nodes = []\n",
    "for node in sorted_nodes:\n",
    "    substituted_nodes.append(node.subs(node,sympy_lscm[node]))\n",
    "\n",
    "\n",
    "print(sorted_nodes)\n",
    "print(substituted_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'z'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:229\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: _Node(\n  (_args): ModuleList(\n    (0-1): 2 x _Node()\n  )\n)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:229\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: _Node()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:229\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: <function _Node.__init__.<locals>.<lambda> at 0x1631b99e0>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m tensor_params \u001b[38;5;241m=\u001b[39m {param: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mfloat\u001b[39m(val), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat) \u001b[38;5;28;01mfor\u001b[39;00m param, val \u001b[38;5;129;01min\u001b[39;00m sympy_string_params\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Run the module with the tensor parameters\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m sympytorch_out \u001b[38;5;241m=\u001b[39m lscm_module(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtensor_params)\n\u001b[1;32m     29\u001b[0m display(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msympy_expressions:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msympy_expressions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m display(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msympy_torch_output:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msympytorch_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:264\u001b[0m, in \u001b[0;36mSymPyModule.forward\u001b[0;34m(self, **symbols)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msymbols: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 264\u001b[0m     out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:264\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msymbols: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 264\u001b[0m     out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:231\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m arg(memodict)\n\u001b[1;32m    232\u001b[0m     memodict[arg] \u001b[38;5;241m=\u001b[39m arg_\n\u001b[1;32m    233\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(arg_)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:231\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m arg(memodict)\n\u001b[1;32m    232\u001b[0m     memodict[arg] \u001b[38;5;241m=\u001b[39m arg_\n\u001b[1;32m    233\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(arg_)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:231\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m arg(memodict)\n\u001b[1;32m    232\u001b[0m     memodict[arg] \u001b[38;5;241m=\u001b[39m arg_\n\u001b[1;32m    233\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(arg_)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:164\u001b[0m, in \u001b[0;36m_Node.__init__.<locals>.<lambda>\u001b[0;34m(memodict)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m value: value\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28;01mlambda\u001b[39;00m memodict: memodict[expr\u001b[38;5;241m.\u001b[39mname]),)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_func \u001b[38;5;241m=\u001b[39m _func_lookup[expr\u001b[38;5;241m.\u001b[39mfunc]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'z'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Substitute the equations to the variables\n",
    "# z = epsilon_z\n",
    "# y = beta_yz * z + epsilon_y\n",
    "# x = beta_xy * y + epsilon_x\n",
    "\n",
    "# Create a list of sympy expressions\n",
    "#sympy_expressions = [z,y,x]\n",
    "\n",
    "sympy_expressions = substituted_nodes\n",
    "\n",
    "# Define parameter values\n",
    "sympy_string_params = {\n",
    "    beta_xy.name: 1.0,\n",
    "    beta_yz.name: 1.0,\n",
    "    epsilon_x.name: 0.1,\n",
    "    epsilon_y.name: 0.1,\n",
    "    epsilon_z.name: 0.1\n",
    "}\n",
    "\n",
    "\n",
    "# Create a sympytorch module from the sympy expressions\n",
    "lscm_module = sympytorch.SymPyModule(expressions=sympy_expressions)\n",
    "\n",
    "# Convert the sympy string parameters to torch tensors\n",
    "tensor_params = {param: torch.tensor(float(val), dtype=torch.float) for param, val in sympy_string_params.items()}\n",
    "\n",
    "# Run the module with the tensor parameters\n",
    "sympytorch_out = lscm_module(**tensor_params)\n",
    "display(f\"sympy_expressions:{sympy_expressions}\")\n",
    "display(f\"sympy_torch_output:{sympytorch_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{x: 0.300000000000000, y: 0.200000000000000, z: 0.100000000000000}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Solve in sympy for comparison\n",
    "sympy_symbol_params = {\n",
    "    beta_xy: 1.0,\n",
    "    beta_yz: 1.0,\n",
    "    epsilon_x: 0.1,\n",
    "    epsilon_y: 0.1,\n",
    "    epsilon_z: 0.1\n",
    "}\n",
    "eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]\n",
    "sympy_out = sy.solve(eqns, list(sympy_lscm), rational=False, dict=False)\n",
    "\n",
    "sympy_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_function():\n",
    "    x, y = sy.symbols(\"x y\")\n",
    "    f = sy.Function(\"f\")\n",
    "    z = x + f(y)\n",
    "    extra_funcs = {f: lambda y_: y_**2}\n",
    "    mod = sympytorch.SymPyModule(expressions=[z], extra_funcs=extra_funcs)\n",
    "    assert mod.sympy() == [z]\n",
    "    assert mod(x=1, y=2) == 1 + 2**2\n",
    "\n",
    "test_custom_function()\n",
    "\n",
    "\n",
    "def test_lscm_function():\n",
    "    x, y, epsilon_x, epsilon_y, beta_xy = sy.symbols(\"x y epsilon_x epsilon_y beta_xy\")\n",
    "    #f = sy.Function(\"f\")\n",
    "    #solution = f(((x,epsilon_x), (y,x*beta_xy+epsilon_y)))\n",
    "    \n",
    "    def solve_lscm(sympy_lscm):\n",
    "        eqns = [sy.Eq(lhs,rhs) for lhs, rhs in sympy_lscm]\n",
    "        #eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]  \n",
    "        return sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "    \n",
    "    #extra_funcs = {f: solve_lscm}\n",
    "    sympy_lscm = ((x,epsilon_x), (y,x*beta_xy+epsilon_y))\n",
    "    eqns = [sy.Eq(lhs,rhs) for lhs, rhs in sympy_lscm]\n",
    "    expressions = sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "    mod = sympytorch.SymPyModule(expressions=expressions)\n",
    "    return mod\n",
    "\n",
    "mod = test_lscm_function()\n",
    "\n",
    "\n",
    "# def solve_lscm(sympy_symbol_params, sympy_lscm):\n",
    "#     eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]   \n",
    "#     sympy_out = sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "    \n",
    "#     return sympy_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m mod(epsilon_x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.1\u001b[39m), epsilon_y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.1\u001b[39m), beta_xy\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m))\n\u001b[1;32m      2\u001b[0m out\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:266\u001b[0m, in \u001b[0;36mSymPyModule.forward\u001b[0;34m(self, **symbols)\u001b[0m\n\u001b[1;32m    264\u001b[0m out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "out = mod(epsilon_x=torch.tensor(0.1), epsilon_y=torch.tensor(0.1), beta_xy=torch.tensor(1.0))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[z, y, x]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sympy_lscm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for var, rhs in sympy_lscm.items():\n",
    "    var = rhs\n",
    "\n",
    "sympy_expressions = [z,y,x]\n",
    "\n",
    "display(sympy_expressions)\n",
    "display(z)\n",
    "\n",
    "# Define parameter values\n",
    "sympy_string_params = {\n",
    "    beta_xy.name: 1.0,\n",
    "    beta_yz.name: 1.0,\n",
    "    epsilon_x.name: 0.1,\n",
    "    epsilon_y.name: 0.1,\n",
    "    epsilon_z.name: 0.1\n",
    "}\n",
    "\n",
    "sympy_symbol_params = {\n",
    "    beta_xy: 1.0,\n",
    "    beta_yz: 1.0,\n",
    "    epsilon_x: 0.1,\n",
    "    epsilon_y: 0.1,\n",
    "    epsilon_z: 0.1\n",
    "}\n",
    "\n",
    "tensor_params = {param: torch.tensor(float(val), dtype=torch.float) for param, val in sympy_string_params.items()}\n",
    "\n",
    "lscm_module = sympytorch.SymPyModule(expressions=sympy_expressions)\n",
    "\n",
    "display(lscm_module.sympy())\n",
    "\n",
    "sympytorch_out = lscm_module(**tensor_params)\n",
    "\n",
    "display(sympy_expressions)\n",
    "display(sympytorch_out)\n",
    "\n",
    "eqns = [sy.Eq(lhs.subs(sympy_symbol_params), rhs.subs(sympy_symbol_params)) for lhs, rhs in sympy_lscm.items()]\n",
    "sympy_out = sy.solve(eqns, list(sympy_lscm), rational=False)\n",
    "\n",
    "display(sympy_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define parameter values\n",
    "sympy_params = {\n",
    "    beta_xy.name: 1.0,\n",
    "    beta_yz.name: 1.0,\n",
    "    epsilon_x.name: 0.1,\n",
    "    epsilon_y.name: 0.1,\n",
    "    epsilon_z.name: 0.1\n",
    "}\n",
    "\n",
    "tensor_params = {param: torch.tensor(float(val), dtype=torch.float) for param, val in sympy_params.items()}\n",
    "\n",
    "lscm_module = sympytorch.SymPyModule(expressions=sympy_expressions)\n",
    "\n",
    "# dictionary of all of the sympy symbols: string name : symbol\n",
    "\n",
    "lscm_module.sympy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# substitute the parameter values into the sympy expressions\n",
    "out = lscm_module(**tensor_params)\n",
    "\n",
    "display(out)\n",
    "\n",
    "\n",
    "# Create the probabilistic graphical model\n",
    "#pg_model = create_pg_model(lscm, params)\n",
    "\n",
    "# Visualize the model\n",
    "#pyro.render_model(lscm_module, render_distributions=True, render_deterministic=True)\n",
    "\n",
    "# # Sample from the model\n",
    "# samples = sample_from_model(pg_model, num_samples=1000)\n",
    "\n",
    "# print(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:229\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: <function _Node.__init__.<locals>.<lambda> at 0x1632ab380>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m X_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate Y using the compiled function\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m Y_tensor \u001b[38;5;241m=\u001b[39m sympy_Y(X\u001b[38;5;241m=\u001b[39mX_tensor)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed Y:\u001b[39m\u001b[38;5;124m\"\u001b[39m, Y_tensor)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate Z using the compiled function, substituting Y\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:264\u001b[0m, in \u001b[0;36mSymPyModule.forward\u001b[0;34m(self, **symbols)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msymbols: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 264\u001b[0m     out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:264\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msymbols: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 264\u001b[0m     out \u001b[38;5;241m=\u001b[39m [node(symbols) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes]\n\u001b[1;32m    265\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:231\u001b[0m, in \u001b[0;36m_Node.forward\u001b[0;34m(self, memodict)\u001b[0m\n\u001b[1;32m    229\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m memodict[arg]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     arg_ \u001b[38;5;241m=\u001b[39m arg(memodict)\n\u001b[1;32m    232\u001b[0m     memodict[arg] \u001b[38;5;241m=\u001b[39m arg_\n\u001b[1;32m    233\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(arg_)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/sympytorch/sympy_module.py:164\u001b[0m, in \u001b[0;36m_Node.__init__.<locals>.<lambda>\u001b[0;34m(memodict)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m value: value\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28;01mlambda\u001b[39;00m memodict: memodict[expr\u001b[38;5;241m.\u001b[39mname]),)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torch_func \u001b[38;5;241m=\u001b[39m _func_lookup[expr\u001b[38;5;241m.\u001b[39mfunc]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Y'"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "import torch\n",
    "from sympytorch import SymPyModule\n",
    "\n",
    "# Step 1: Define symbols\n",
    "X, Y, Z = sp.symbols('X Y Z')\n",
    "\n",
    "# Step 2: Define the SCM\n",
    "expr_Y = 2*X + 3\n",
    "expr_Z = X**2 + Y\n",
    "\n",
    "# Step 3: Compile expressions to PyTorch functions\n",
    "# For each symbolic expression, create a SymPyModule\n",
    "sympy_mod = SymPyModule(expressions=[Y, expr_Y, Z, expr_Z])\n",
    "#sympy_Y = SymPyModule(expressions=[Y, expr_Y])\n",
    "#sympy_Z = SymPyModule(expressions=[Z, expr_Z])\n",
    "\n",
    "# Step 4: Convert inputs to PyTorch tensors and evaluate\n",
    "# For instance, using a tensor input for X\n",
    "X_tensor = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Calculate Y using the compiled function\n",
    "Y_tensor = sympy_Y(X=X_tensor)\n",
    "print(\"Computed Y:\", Y_tensor)\n",
    "\n",
    "# Calculate Z using the compiled function, substituting Y\n",
    "Z_tensor = sympy_Z(X=X_tensor, Y=Y_tensor)\n",
    "print(\"Computed Z:\", Z_tensor)\n",
    "\n",
    "# You can also perform gradient computations if required\n",
    "Z_tensor.sum().backward()\n",
    "print(\"Gradient of X:\", X_tensor.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"609pt\" height=\"381pt\"\n",
       " viewBox=\"0.00 0.00 608.56 380.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 376.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-376.5 604.56,-376.5 604.56,4 -4,4\"/>\n",
       "<!-- epsilon_X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>epsilon_X</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"258.79\" cy=\"-294.25\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.79\" y=\"-289.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_X</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"258.79\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.79\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- epsilon_X&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>epsilon_X&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M258.79,-275.95C258.79,-254.45 258.79,-217.43 258.79,-191.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.29,-191.88 258.79,-181.88 255.29,-191.88 262.29,-191.88\"/>\n",
       "</g>\n",
       "<!-- epsilon_Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>epsilon_Y</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"48.79\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"48.79\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Y</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"183.79\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- epsilon_Y&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>epsilon_Y&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M76.11,-146.83C98.43,-135.26 129.95,-118.92 153.13,-106.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.52,-110.12 161.78,-102.41 151.3,-103.91 154.52,-110.12\"/>\n",
       "</g>\n",
       "<!-- epsilon_Z -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>epsilon_Z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"324.79\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Z</text>\n",
       "</g>\n",
       "<!-- Z -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>Z</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"324.79\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.79\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Z</text>\n",
       "</g>\n",
       "<!-- epsilon_Z&#45;&gt;Z -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>epsilon_Z&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M324.79,-71.7C324.79,-64.41 324.79,-55.73 324.79,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"328.29,-47.62 324.79,-37.62 321.29,-47.62 328.29,-47.62\"/>\n",
       "</g>\n",
       "<!-- beta_X_Y -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>beta_X_Y</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"164.79\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"164.79\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Y</text>\n",
       "</g>\n",
       "<!-- beta_X_Y&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>beta_X_Y&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.49,-143.7C171.51,-136.24 173.93,-127.32 176.2,-118.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"179.51,-120.13 178.75,-109.57 172.76,-118.3 179.51,-120.13\"/>\n",
       "</g>\n",
       "<!-- beta_X_Z -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>beta_X_Z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"438.79\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"438.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Z</text>\n",
       "</g>\n",
       "<!-- beta_X_Z&#45;&gt;Z -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>beta_X_Z&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M414.62,-74.15C396.78,-63.2 372.43,-48.25 353.58,-36.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.67,-33.85 345.32,-31.6 352.01,-39.82 355.67,-33.85\"/>\n",
       "</g>\n",
       "<!-- beta_Y_Z -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>beta_Y_Z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"552.79\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"552.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_Y_Z</text>\n",
       "</g>\n",
       "<!-- beta_Y_Z&#45;&gt;Z -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>beta_Y_Z&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M516.67,-77.91C473.76,-64.74 402.67,-42.91 360.12,-29.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.22,-26.52 350.63,-26.93 359.16,-33.21 361.22,-26.52\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.62,-146.83C233.14,-137.06 219.02,-123.88 207.13,-112.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"209.75,-110.44 200.05,-106.18 204.98,-115.56 209.75,-110.44\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Z -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>X&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M257.05,-143.62C255.95,-124.92 256.46,-94.81 267.79,-72 274.42,-58.67 285.89,-47 296.82,-38.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.77,-40.95 304.55,-32.07 294.5,-35.4 298.77,-40.95\"/>\n",
       "</g>\n",
       "<!-- Y&#45;&gt;Z -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Y&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M204.9,-78.52C228.37,-66.87 266.51,-47.94 293.46,-34.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"294.78,-37.81 302.18,-30.22 291.67,-31.54 294.78,-37.81\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-355.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_X ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-338.7\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Y ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-322.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-305.7\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Y ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-289.2\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-272.7\" font-family=\"Times,serif\" font-size=\"14.00\">beta_Y_Z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-256.2\" font-family=\"Times,serif\" font-size=\"14.00\">X ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-239.7\" font-family=\"Times,serif\" font-size=\"14.00\">Y ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-223.2\" font-family=\"Times,serif\" font-size=\"14.00\">Z ~ Deterministic</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x347227950>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx \n",
    "import sympy as sp \n",
    "import pyro\n",
    "from sympytorch import SymPyModule\n",
    "import pyro.distributions as dist\n",
    "\n",
    "def compile_lscm_to_pyro(DAG: nx.DiGraph) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Compiles a Linear Structural Causal Model (LSCM) represented as a directed acyclic graph (DAG) into a Pyro model.\n",
    "    Parameters:\n",
    "    DAG (nx.DiGraph): A directed acyclic graph where nodes represent variables and edges represent causal relationships.\n",
    "                      Each node should have an 'expression' attribute containing a sympy expression for the variable.\n",
    "    Returns:\n",
    "    nx.DiGraph: The input DAG with additional attributes for each node:\n",
    "                - 'pyro_deterministic': The deterministic Pyro value for the node, computed based on the LSCM.\n",
    "    \"\"\"\n",
    "    symbols = list(nx.topological_sort(DAG))\n",
    "    expressions = nx.get_node_attributes(DAG, 'expression')\n",
    "    \n",
    "    sympy_modules = {symbol: SymPyModule(expressions=[expressions[symbol]]) for symbol in symbols}\n",
    "    \n",
    "    epsilon_samples = {symbol: pyro.sample(f'epsilon_{symbol}', dist.Normal(0, 1)) for symbol in symbols}\n",
    "    beta_samples = {}\n",
    "    for parent, child in DAG.edges:\n",
    "        beta_samples[(parent, child)] = pyro.sample(f'beta_{parent}_{child}', dist.Normal(0, 1))\n",
    "        DAG.edges[parent, child]['beta'] = beta_samples[(parent, child)]\n",
    "    \n",
    "    pyro_deterministic_values = {}\n",
    "    for symbol in symbols:\n",
    "        input_params = {f'epsilon_{symbol}': epsilon_samples[symbol]}\n",
    "        for parent in DAG.predecessors(symbol):\n",
    "            input_params[parent.name] = pyro_deterministic_values[parent]\n",
    "            input_params[f'beta_{parent}_{symbol}'] = DAG.edges[parent, symbol]['beta']\n",
    "        pyro_deterministic_values[symbol] = pyro.deterministic(symbol.name, sympy_modules[symbol](**input_params)).squeeze()\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        DAG.nodes[symbol]['pyro_deterministic'] = pyro_deterministic_values[symbol]\n",
    "    \n",
    "    return DAG\n",
    "\n",
    "# Define the symbols and expressions\n",
    "X, Y, Z = sp.symbols('X Y Z')\n",
    "beta_XY, beta_YZ, beta_XZ = sp.symbols('beta_X_Y beta_Y_Z beta_X_Z')\n",
    "epsilon_X, epsilon_Y, epsilon_Z = sp.symbols('epsilon_X epsilon_Y epsilon_Z')\n",
    "\n",
    "# Create the DAG\n",
    "G = nx.DiGraph()\n",
    "G.add_node(X, expression=sp.tanh(epsilon_X)+1)\n",
    "G.add_node(Y, expression=sp.tanh(beta_XY * X + epsilon_Y)+1)\n",
    "G.add_node(Z, expression=sp.tanh(beta_YZ * Y + beta_XZ * X + epsilon_Z)+1)\n",
    "G.add_edges_from([(X, Y), (Y, Z), (X, Z)])\n",
    "\n",
    "G_original = G.copy()\n",
    "\n",
    "# Compile the LSCM to Pyro\n",
    "DAG_with_deterministic = compile_lscm_to_pyro(G)\n",
    "\n",
    "nx.draw(DAG_with_deterministic, with_labels=True, node_size=2000, node_color='skyblue', font_size=15, font_color='black', font_weight='bold')\n",
    " \n",
    " \n",
    "\n",
    "# Visualize the model\n",
    "pyro.render_model(compile_lscm_to_pyro, model_args=(G,), render_distributions=True, render_deterministic=True, filename=\"LSCM_graph.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{X: epsilon_X,\n",
       " Y: X*beta_X_Y + epsilon_Y,\n",
       " Z: X*beta_X_Z + Y*beta_Y_Z + epsilon_Z}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"609pt\" height=\"381pt\"\n",
       " viewBox=\"0.00 0.00 608.56 380.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 376.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-376.5 604.56,-376.5 604.56,4 -4,4\"/>\n",
       "<!-- epsilon_X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>epsilon_X</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"258.79\" cy=\"-294.25\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.79\" y=\"-289.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_X</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"258.79\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.79\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- epsilon_X&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>epsilon_X&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M258.79,-275.95C258.79,-254.45 258.79,-217.43 258.79,-191.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.29,-191.88 258.79,-181.88 255.29,-191.88 262.29,-191.88\"/>\n",
       "</g>\n",
       "<!-- epsilon_Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>epsilon_Y</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"48.79\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"48.79\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Y</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"183.79\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- epsilon_Y&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>epsilon_Y&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M76.11,-146.83C98.43,-135.26 129.95,-118.92 153.13,-106.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.52,-110.12 161.78,-102.41 151.3,-103.91 154.52,-110.12\"/>\n",
       "</g>\n",
       "<!-- epsilon_Z -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>epsilon_Z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"324.79\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Z</text>\n",
       "</g>\n",
       "<!-- Z -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>Z</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"324.79\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.79\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Z</text>\n",
       "</g>\n",
       "<!-- epsilon_Z&#45;&gt;Z -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>epsilon_Z&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M324.79,-71.7C324.79,-64.41 324.79,-55.73 324.79,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"328.29,-47.62 324.79,-37.62 321.29,-47.62 328.29,-47.62\"/>\n",
       "</g>\n",
       "<!-- beta_X_Y -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>beta_X_Y</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"164.79\" cy=\"-162\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"164.79\" y=\"-156.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Y</text>\n",
       "</g>\n",
       "<!-- beta_X_Y&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>beta_X_Y&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M169.49,-143.7C171.51,-136.24 173.93,-127.32 176.2,-118.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"179.51,-120.13 178.75,-109.57 172.76,-118.3 179.51,-120.13\"/>\n",
       "</g>\n",
       "<!-- beta_X_Z -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>beta_X_Z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"438.79\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"438.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Z</text>\n",
       "</g>\n",
       "<!-- beta_X_Z&#45;&gt;Z -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>beta_X_Z&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M414.62,-74.15C396.78,-63.2 372.43,-48.25 353.58,-36.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.67,-33.85 345.32,-31.6 352.01,-39.82 355.67,-33.85\"/>\n",
       "</g>\n",
       "<!-- beta_Y_Z -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>beta_Y_Z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"552.79\" cy=\"-90\" rx=\"47.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"552.79\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">beta_Y_Z</text>\n",
       "</g>\n",
       "<!-- beta_Y_Z&#45;&gt;Z -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>beta_Y_Z&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M516.67,-77.91C473.76,-64.74 402.67,-42.91 360.12,-29.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.22,-26.52 350.63,-26.93 359.16,-33.21 361.22,-26.52\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.62,-146.83C233.14,-137.06 219.02,-123.88 207.13,-112.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"209.75,-110.44 200.05,-106.18 204.98,-115.56 209.75,-110.44\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Z -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>X&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M257.05,-143.62C255.95,-124.92 256.46,-94.81 267.79,-72 274.42,-58.67 285.89,-47 296.82,-38.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.77,-40.95 304.55,-32.07 294.5,-35.4 298.77,-40.95\"/>\n",
       "</g>\n",
       "<!-- Y&#45;&gt;Z -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Y&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M204.9,-78.52C228.37,-66.87 266.51,-47.94 293.46,-34.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"294.78,-37.81 302.18,-30.22 291.67,-31.54 294.78,-37.81\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-355.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_X ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-338.7\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Y ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-322.2\" font-family=\"Times,serif\" font-size=\"14.00\">epsilon_Z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-305.7\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Y ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-289.2\" font-family=\"Times,serif\" font-size=\"14.00\">beta_X_Z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-272.7\" font-family=\"Times,serif\" font-size=\"14.00\">beta_Y_Z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-256.2\" font-family=\"Times,serif\" font-size=\"14.00\">X ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-239.7\" font-family=\"Times,serif\" font-size=\"14.00\">Y ~ Deterministic</text>\n",
       "<text text-anchor=\"start\" x=\"333.54\" y=\"-223.2\" font-family=\"Times,serif\" font-size=\"14.00\">Z ~ Deterministic</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x177a44d10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from LSCM graph to LSCM dictionary\n",
    "symbol_expression_dict = {symbol: G_original.nodes[symbol]['expression'] for symbol in G_original.nodes}\n",
    "\n",
    "# Display the dictionary\n",
    "display(symbol_expression_dict)\n",
    "\n",
    "def scm_dict_to_dag(symbol_expression_dict):\n",
    "    \"\"\"\n",
    "    Converts a dictionary of symbolic expressions into a directed acyclic graph (DAG).\n",
    "    Parameters:\n",
    "    symbol_expression_dict (dict): A dictionary where keys are symbols and values are symbolic expressions.\n",
    "    Returns:\n",
    "    networkx.DiGraph: A directed acyclic graph where nodes represent symbols and edges represent dependencies between symbols based on their expressions.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for symbol, expression in symbol_expression_dict.items():\n",
    "        G.add_node(symbol, expression=expression)\n",
    "        for sub_expr in expression.free_symbols:\n",
    "            # If a symbol from the expression is a state variable (dict key), add an edge\n",
    "            if sub_expr in symbol_expression_dict:\n",
    "                G.add_edge(sub_expr, symbol)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Convert the dictionary to a DAG\n",
    "dag_from_dict = scm_dict_to_dag(symbol_expression_dict)\n",
    "\n",
    "# check that the converted DAG equals the original DAG\n",
    "assert nx.utils.graphs_equal(G_original, dag_from_dict)\n",
    "\n",
    "# get adjacency matrix \n",
    "adj_matrix = nx.adjacency_matrix(dag_from_dict).toarray()\n",
    "display(adj_matrix)\n",
    "\n",
    "# Compile the converted DAG to Pyro\n",
    "DAG_with_deterministic_converted = compile_lscm_to_pyro(dag_from_dict)\n",
    "pyro.render_model(compile_lscm_to_pyro, model_args=(DAG_with_deterministic_converted,), render_distributions=True, render_deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epsilon_X': tensor([ 0.3027, -0.6539, -0.0661]),\n",
       " 'epsilon_Y': tensor([ 0.4583,  0.3942, -0.4886]),\n",
       " 'epsilon_Z': tensor([ 0.1659, -1.4127, -0.4557]),\n",
       " 'beta_X_Y': tensor([0.4985, 0.2082, 0.9355]),\n",
       " 'beta_X_Z': tensor([ 0.8547, -1.3521, -0.2218]),\n",
       " 'beta_Y_Z': tensor([0.6094, 0.7802, 2.2423]),\n",
       " 'X': tensor([[1.2938],\n",
       "         [0.4257],\n",
       "         [0.9340]]),\n",
       " 'Y': tensor([[1.8016],\n",
       "         [1.4485],\n",
       "         [1.3671]]),\n",
       " 'Z': tensor([[1.9827],\n",
       "         [0.3047],\n",
       "         [1.9838]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{X: tensor([[1.],\n",
       "         [0.],\n",
       "         [1.]]),\n",
       " Y: tensor([[1.],\n",
       "         [3.],\n",
       "         [4.]]),\n",
       " Z: tensor([[0.],\n",
       "         [0.],\n",
       "         [3.]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('X_obs_observed',\n",
       "              {'type': 'sample',\n",
       "               'name': 'X_obs_observed',\n",
       "               'fn': Poisson(rate: 1.0776443481445312),\n",
       "               'is_observed': True,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': tensor([[1.],\n",
       "                       [0.],\n",
       "                       [1.]]),\n",
       "               'infer': {},\n",
       "               'scale': 1.0,\n",
       "               'mask': tensor([[True],\n",
       "                       [True],\n",
       "                       [True]]),\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None}),\n",
       "             ('X_obs_unobserved',\n",
       "              {'type': 'sample',\n",
       "               'name': 'X_obs_unobserved',\n",
       "               'fn': Poisson(rate: 1.0776443481445312),\n",
       "               'is_observed': False,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': Provenance:\n",
       "               frozenset({'X'})\n",
       "               Tensor:\n",
       "               1.0,\n",
       "               'infer': {},\n",
       "               'scale': 1.0,\n",
       "               'mask': tensor([[False],\n",
       "                       [False],\n",
       "                       [False]]),\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None}),\n",
       "             ('X_obs',\n",
       "              {'type': 'sample',\n",
       "               'name': 'X_obs',\n",
       "               'fn': MaskedDistribution(),\n",
       "               'is_observed': True,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': Provenance:\n",
       "               frozenset({'X'})\n",
       "               Tensor:\n",
       "               tensor([[1.],\n",
       "                       [0.],\n",
       "                       [1.]]),\n",
       "               'infer': {'_deterministic': True},\n",
       "               'scale': 1.0,\n",
       "               'mask': None,\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None}),\n",
       "             ('Y_obs_observed',\n",
       "              {'type': 'sample',\n",
       "               'name': 'Y_obs_observed',\n",
       "               'fn': Poisson(rate: 1.8970000743865967),\n",
       "               'is_observed': True,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': tensor([[1.],\n",
       "                       [3.],\n",
       "                       [4.]]),\n",
       "               'infer': {},\n",
       "               'scale': 1.0,\n",
       "               'mask': tensor([[True],\n",
       "                       [True],\n",
       "                       [True]]),\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None}),\n",
       "             ('Y_obs_unobserved',\n",
       "              {'type': 'sample',\n",
       "               'name': 'Y_obs_unobserved',\n",
       "               'fn': Poisson(rate: 1.8970000743865967),\n",
       "               'is_observed': False,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': Provenance:\n",
       "               frozenset({'Y'})\n",
       "               Tensor:\n",
       "               2.0,\n",
       "               'infer': {},\n",
       "               'scale': 1.0,\n",
       "               'mask': tensor([[False],\n",
       "                       [False],\n",
       "                       [False]]),\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None}),\n",
       "             ('Y_obs',\n",
       "              {'type': 'sample',\n",
       "               'name': 'Y_obs',\n",
       "               'fn': MaskedDistribution(),\n",
       "               'is_observed': True,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': Provenance:\n",
       "               frozenset({'Y'})\n",
       "               Tensor:\n",
       "               tensor([[1.],\n",
       "                       [3.],\n",
       "                       [4.]]),\n",
       "               'infer': {'_deterministic': True},\n",
       "               'scale': 1.0,\n",
       "               'mask': None,\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None}),\n",
       "             ('Z_obs_observed',\n",
       "              {'type': 'sample',\n",
       "               'name': 'Z_obs_observed',\n",
       "               'fn': Poisson(rate: 0.01780170202255249),\n",
       "               'is_observed': True,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': tensor([[0.],\n",
       "                       [0.],\n",
       "                       [3.]]),\n",
       "               'infer': {},\n",
       "               'scale': 1.0,\n",
       "               'mask': tensor([[True],\n",
       "                       [True],\n",
       "                       [True]]),\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None}),\n",
       "             ('Z_obs_unobserved',\n",
       "              {'type': 'sample',\n",
       "               'name': 'Z_obs_unobserved',\n",
       "               'fn': Poisson(rate: 0.01780170202255249),\n",
       "               'is_observed': False,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': Provenance:\n",
       "               frozenset({'Z'})\n",
       "               Tensor:\n",
       "               0.0,\n",
       "               'infer': {},\n",
       "               'scale': 1.0,\n",
       "               'mask': tensor([[False],\n",
       "                       [False],\n",
       "                       [False]]),\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None}),\n",
       "             ('Z_obs',\n",
       "              {'type': 'sample',\n",
       "               'name': 'Z_obs',\n",
       "               'fn': MaskedDistribution(),\n",
       "               'is_observed': True,\n",
       "               'args': (),\n",
       "               'kwargs': {},\n",
       "               'value': Provenance:\n",
       "               frozenset({'Z'})\n",
       "               Tensor:\n",
       "               tensor([[0.],\n",
       "                       [0.],\n",
       "                       [3.]]),\n",
       "               'infer': {'_deterministic': True},\n",
       "               'scale': 1.0,\n",
       "               'mask': None,\n",
       "               'cond_indep_stack': (),\n",
       "               'done': True,\n",
       "               'stop': False,\n",
       "               'continuation': None})])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from pyro.infer import Predictive\n",
    "\n",
    "def create_observation_model(compiled_DAG: nx.DiGraph, data):\n",
    "    \"\"\"Create an observation model from a compiled LSCM DAG\"\"\"\n",
    "    obs_mask = {node: ~torch.isnan(data[node]) for node in compiled_DAG.nodes}\n",
    "    for node in compiled_DAG.nodes:\n",
    "        pyro.sample(f\"{node}_obs\", dist.Poisson(compiled_DAG.nodes[node]['pyro_deterministic']), obs=data[node], obs_mask=obs_mask[node])\n",
    "    return compiled_DAG\n",
    "\n",
    "prior_predictive = Predictive(compile_lscm_to_pyro, num_samples=3)\n",
    "prior_samples = prior_predictive(G_original)\n",
    "display(prior_samples)\n",
    "ground_truth_samples = {node: dist.Poisson(prior_samples[node.name]).sample() for node in G_original.nodes}\n",
    "display(ground_truth_samples)\n",
    "\n",
    "# Create the observation model\n",
    "# obs_samples = create_observation_model(DAG_with_deterministic, data=ground_truth_samples)\n",
    "with pyro.poutine.trace() as tr:\n",
    "    create_observation_model(DAG_with_deterministic, data=ground_truth_samples)\n",
    "\n",
    "display(tr.trace.nodes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(pyro_lightning_module, train_dataloaders\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader([data], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    540\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:957\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m    956\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:158\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_optimizers(trainer)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_precision_plugin()\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:138\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates optimizers and schedulers.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    trainer: the Trainer, these optimizers should be connected to\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler_configs \u001b[38;5;241m=\u001b[39m _init_optimizers_and_lr_schedulers(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:179\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls `LightningModule.configure_optimizers` and parses and validates the output.\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call\n\u001b[0;32m--> 179\u001b[0m optim_conf \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(model\u001b[38;5;241m.\u001b[39mtrainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigure_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim_conf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     rank_zero_warn(\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    170\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "Cell \u001b[0;32mIn[62], line 24\u001b[0m, in \u001b[0;36mPyroLightningModule.configure_optimizers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure_optimizers\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr)\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(params, defaults)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/miniconda3/envs/NOCAP_DEV_env/lib/python3.11/site-packages/torch/optim/optimizer.py:279\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    277\u001b[0m param_groups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer got an empty parameter list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    281\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoNormal\n",
    "from pyro.optim import Adam\n",
    "\n",
    "import pyro.distributions as dist   \n",
    "\n",
    "class PyroLightningModule(pl.LightningModule):\n",
    "    def __init__(self, model, guide, dag, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.guide = guide\n",
    "        self.dag = dag\n",
    "        self.lr = lr\n",
    "        self.svi = SVI(model, guide, Adam({\"lr\": lr}), loss=Trace_ELBO())\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.svi.step(**batch)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    # def model(self, dag):\n",
    "    #     return self.model(dag)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "# # Define the observation model\n",
    "# def observation_model(data):\n",
    "#     for node in DAG_with_deterministic.nodes:\n",
    "#         pyro.sample(f\"{node}_obs\", dist.Poisson(DAG_with_deterministic.nodes[node]['pyro_deterministic']), obs=data[node])\n",
    "\n",
    "# Define the guide\n",
    "guide = AutoNormal(create_observation_model )\n",
    "\n",
    "# Prepare the data\n",
    "data = {node: ground_truth_samples[node] for node in DAG_with_deterministic.nodes}\n",
    "\n",
    "# Create the Pyro Lightning module\n",
    "pyro_lightning_module = PyroLightningModule(create_observation_model, guide, dag=DAG_with_deterministic)\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(max_epochs=1000)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(pyro_lightning_module, train_dataloaders=torch.utils.data.DataLoader([data], batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NOCAP_DEV_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
